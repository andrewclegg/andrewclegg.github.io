<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>The Plural of Anecdote</title><link>http://www.andrewclegg.org/</link><description></description><atom:link href="http://www.andrewclegg.org/feeds/andrew-clegg.rss.xml" rel="self"></atom:link><lastBuildDate>Sun, 28 May 2017 00:00:00 +0100</lastBuildDate><item><title>Optimizing TensorFlow for your laptop’s CPU</title><link>http://www.andrewclegg.org/tech/TensorFlowLaptopCPU.html</link><description>&lt;p&gt;I&amp;#8217;ve recently been teaching myself &lt;a href="https://www.tensorflow.org"&gt;TensorFlow&lt;/a&gt;, and haven&amp;#8217;t spent the time and money to set up a cloud server (or physical machine!) with a &lt;span class="caps"&gt;GPU&lt;/span&gt;. I was originally running it from a pre-built Docker image, inside a Jupyter notebook, and saw a bunch of warnings like this in the console&amp;nbsp;output:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;W&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;core&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;platform&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;cpu_feature_guard&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cc&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;45&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;The&lt;/span&gt; &lt;span class="n"&gt;TensorFlow&lt;/span&gt; &lt;span class="n"&gt;library&lt;/span&gt; &lt;span class="n"&gt;wasn&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="n"&gt;compiled&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;use&lt;/span&gt; &lt;span class="n"&gt;SSE3&lt;/span&gt; &lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;but&lt;/span&gt; &lt;span class="n"&gt;these&lt;/span&gt; &lt;span class="n"&gt;are&lt;/span&gt; &lt;span class="n"&gt;available&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;your&lt;/span&gt; &lt;span class="n"&gt;machine&lt;/span&gt; &lt;span class="n"&gt;and&lt;/span&gt; &lt;span class="n"&gt;could&lt;/span&gt; &lt;span class="n"&gt;speed&lt;/span&gt; &lt;span class="n"&gt;up&lt;/span&gt; &lt;span class="n"&gt;CPU&lt;/span&gt; &lt;span class="n"&gt;computations&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;span class="n"&gt;W&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;core&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;platform&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;cpu_feature_guard&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cc&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;45&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;The&lt;/span&gt; &lt;span class="n"&gt;TensorFlow&lt;/span&gt; &lt;span class="n"&gt;library&lt;/span&gt; &lt;span class="n"&gt;wasn&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="n"&gt;compiled&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;use&lt;/span&gt; &lt;span class="n"&gt;SSE4&lt;/span&gt;&lt;span class="mf"&gt;.1&lt;/span&gt; &lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;but&lt;/span&gt; &lt;span class="n"&gt;these&lt;/span&gt; &lt;span class="n"&gt;are&lt;/span&gt; &lt;span class="n"&gt;available&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;your&lt;/span&gt; &lt;span class="n"&gt;machine&lt;/span&gt; &lt;span class="n"&gt;and&lt;/span&gt; &lt;span class="n"&gt;could&lt;/span&gt; &lt;span class="n"&gt;speed&lt;/span&gt; &lt;span class="n"&gt;up&lt;/span&gt; &lt;span class="n"&gt;CPU&lt;/span&gt; &lt;span class="n"&gt;computations&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;span class="n"&gt;W&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;core&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;platform&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;cpu_feature_guard&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cc&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;45&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;The&lt;/span&gt; &lt;span class="n"&gt;TensorFlow&lt;/span&gt; &lt;span class="n"&gt;library&lt;/span&gt; &lt;span class="n"&gt;wasn&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="n"&gt;compiled&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;use&lt;/span&gt; &lt;span class="n"&gt;SSE4&lt;/span&gt;&lt;span class="mf"&gt;.2&lt;/span&gt; &lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;but&lt;/span&gt; &lt;span class="n"&gt;these&lt;/span&gt; &lt;span class="n"&gt;are&lt;/span&gt; &lt;span class="n"&gt;available&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;your&lt;/span&gt; &lt;span class="n"&gt;machine&lt;/span&gt; &lt;span class="n"&gt;and&lt;/span&gt; &lt;span class="n"&gt;could&lt;/span&gt; &lt;span class="n"&gt;speed&lt;/span&gt; &lt;span class="n"&gt;up&lt;/span&gt; &lt;span class="n"&gt;CPU&lt;/span&gt; &lt;span class="n"&gt;computations&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;span class="n"&gt;W&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;core&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;platform&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;cpu_feature_guard&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cc&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;45&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;The&lt;/span&gt; &lt;span class="n"&gt;TensorFlow&lt;/span&gt; &lt;span class="n"&gt;library&lt;/span&gt; &lt;span class="n"&gt;wasn&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="n"&gt;compiled&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;use&lt;/span&gt; &lt;span class="n"&gt;AVX&lt;/span&gt; &lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;but&lt;/span&gt; &lt;span class="n"&gt;these&lt;/span&gt; &lt;span class="n"&gt;are&lt;/span&gt; &lt;span class="n"&gt;available&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;your&lt;/span&gt; &lt;span class="n"&gt;machine&lt;/span&gt; &lt;span class="n"&gt;and&lt;/span&gt; &lt;span class="n"&gt;could&lt;/span&gt; &lt;span class="n"&gt;speed&lt;/span&gt; &lt;span class="n"&gt;up&lt;/span&gt; &lt;span class="n"&gt;CPU&lt;/span&gt; &lt;span class="n"&gt;computations&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;span class="n"&gt;W&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;core&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;platform&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;cpu_feature_guard&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cc&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;45&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;The&lt;/span&gt; &lt;span class="n"&gt;TensorFlow&lt;/span&gt; &lt;span class="n"&gt;library&lt;/span&gt; &lt;span class="n"&gt;wasn&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="n"&gt;compiled&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;use&lt;/span&gt; &lt;span class="n"&gt;AVX2&lt;/span&gt; &lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;but&lt;/span&gt; &lt;span class="n"&gt;these&lt;/span&gt; &lt;span class="n"&gt;are&lt;/span&gt; &lt;span class="n"&gt;available&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;your&lt;/span&gt; &lt;span class="n"&gt;machine&lt;/span&gt; &lt;span class="n"&gt;and&lt;/span&gt; &lt;span class="n"&gt;could&lt;/span&gt; &lt;span class="n"&gt;speed&lt;/span&gt; &lt;span class="n"&gt;up&lt;/span&gt; &lt;span class="n"&gt;CPU&lt;/span&gt; &lt;span class="n"&gt;computations&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;span class="n"&gt;W&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;core&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;platform&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;cpu_feature_guard&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cc&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;45&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;The&lt;/span&gt; &lt;span class="n"&gt;TensorFlow&lt;/span&gt; &lt;span class="n"&gt;library&lt;/span&gt; &lt;span class="n"&gt;wasn&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="n"&gt;compiled&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;use&lt;/span&gt; &lt;span class="n"&gt;FMA&lt;/span&gt; &lt;span class="n"&gt;instructions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;but&lt;/span&gt; &lt;span class="n"&gt;these&lt;/span&gt; &lt;span class="n"&gt;are&lt;/span&gt; &lt;span class="n"&gt;available&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;your&lt;/span&gt; &lt;span class="n"&gt;machine&lt;/span&gt; &lt;span class="n"&gt;and&lt;/span&gt; &lt;span class="n"&gt;could&lt;/span&gt; &lt;span class="n"&gt;speed&lt;/span&gt; &lt;span class="n"&gt;up&lt;/span&gt; &lt;span class="n"&gt;CPU&lt;/span&gt; &lt;span class="n"&gt;computations&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The pre-built versions available through Docker, pip etc. tend to go for wide compatibility, which means disabling a bunch of optional speedups that aren&amp;#8217;t supported on all hardware. Thankfully, it turns out not to be too hard to build it from scratch yourself, which lets you switch all this good stuff on, and makes the process of experimentation and learning a bit less&amp;nbsp;tedious.&lt;/p&gt;
&lt;p&gt;This could also be useful if you&amp;#8217;re training a model that&amp;#8217;s just too damn big to fit on &lt;span class="caps"&gt;GPU&lt;/span&gt; hardware that you can actually afford, or if you want to train on GPUs but squeeze extra performance out of cheap &lt;span class="caps"&gt;CPU&lt;/span&gt;-based inference servers at query&amp;nbsp;time.&lt;/p&gt;
&lt;p&gt;Here&amp;#8217;s a walkthrough of how I did it, on a 2016 Macbook Pro running Sierra (10.12.5). I expect the steps for Windows and Linux are similar. There are quite a few prerequisites, but it&amp;#8217;s fairly likely you have some of these&amp;nbsp;already.&lt;/p&gt;
&lt;h3&gt;Xcode&lt;/h3&gt;
&lt;p&gt;First off you&amp;#8217;ll need Xcode if you don&amp;#8217;t already have it, you can get this from the App&amp;nbsp;Store.&lt;/p&gt;
&lt;h3&gt;Python&lt;/h3&gt;
&lt;p&gt;TensorFlow works with various different versions of Python, I believe, but I was using the &lt;a href="https://www.continuum.io/downloads"&gt;Anaconda distribution&lt;/a&gt; of Python&amp;nbsp;2.7.&lt;/p&gt;
&lt;h3&gt;Homebrew&lt;/h3&gt;
&lt;p&gt;You&amp;#8217;ll need this if you don&amp;#8217;t have it already, in order to install Bazel (see below). Download it from &lt;a href="https://brew.sh"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Java&lt;/h3&gt;
&lt;p&gt;Bazel also requires &lt;span class="caps"&gt;JDK8&lt;/span&gt; which you can get from &lt;a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html"&gt;Oracle&lt;/a&gt;. I used 1.8.0_131 which was the latest at time of writing, but I don&amp;#8217;t think it matters too&amp;nbsp;much.&lt;/p&gt;
&lt;h3&gt;Bazel&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://bazel.build"&gt;Bazel&lt;/a&gt; is Google&amp;#8217;s build tool which is used to compile and package &lt;span class="caps"&gt;TF&lt;/span&gt;. Once Homebrew and Java are installed &amp;#8212; you may want to log out and log back in again to make sure environment variables etc. are set up right &amp;#8212; you can install Bazel by&amp;nbsp;typing:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;brew&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;bazel&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;TensorFlow&lt;/h3&gt;
&lt;p&gt;Finally we can actually install TensorFlow&amp;nbsp;itself.&lt;/p&gt;
&lt;p&gt;I created a Conda environment to work in,&amp;nbsp;first:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;conda&lt;/span&gt; &lt;span class="n"&gt;create&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;
&lt;span class="n"&gt;source&lt;/span&gt; &lt;span class="n"&gt;activate&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Although I think this is a bit moot, as the pip install step (see below) seems to install it into your Conda site-packages and make it available in all environments&amp;nbsp;automatically.&lt;/p&gt;
&lt;p&gt;Then checkout TensorFlow from &lt;a href="https://github.com/tensorflow/tensorflow"&gt;GitHub&lt;/a&gt; and cd into your local copy,&amp;nbsp;and&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;configure&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;to configure the build. You can switch on various optional features here, it&amp;#8217;s probably fine to leave everything as defaults though. The actual options we&amp;#8217;re interested in aren&amp;#8217;t controlled here, but via command line params when you actually build&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;That&amp;#8217;s done by typing the&amp;nbsp;following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;bazel&lt;/span&gt; &lt;span class="n"&gt;build&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="n"&gt;opt&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;copt&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="n"&gt;mavx&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;copt&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="n"&gt;mavx2&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;copt&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="n"&gt;mfma&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;copt&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="n"&gt;msse4&lt;/span&gt;&lt;span class="mf"&gt;.2&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="c1"&gt;//tensorflow/tools/pip_package:build_pip_package&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will compile &lt;span class="caps"&gt;TF&lt;/span&gt; itself, and also output a script to generate a Python package. Be warned, this will take a while! Well over an hour, probably more like two. I didn&amp;#8217;t time it&amp;nbsp;exactly.&lt;/p&gt;
&lt;p&gt;On some platforms you need to add &lt;code&gt;--copt=-mfpmath=both&lt;/code&gt; to the set of flags above, but recent versions of clang provided with macOS don&amp;#8217;t need this, and will barf if you&amp;nbsp;do.&lt;/p&gt;
&lt;p&gt;Once it&amp;#8217;s finished, you need to bundle it into a pip wheel &amp;#8212; a binary distribution with a Python&amp;nbsp;wrapper:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;bazel&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;bin&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;tools&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;pip_package&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;build_pip_package&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;tmp&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;tensorflow_pkg&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Then you can install this into your Conda environment. First, double-check your paths are set up right by typing &lt;code&gt;which pip&lt;/code&gt; &amp;#8212; it should be pointing to a version of pip in your anaconda install directory. Then&amp;nbsp;type:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nx"&gt;pip&lt;/span&gt; &lt;span class="nb"&gt;install&lt;/span&gt; &lt;span class="p"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;tmp&lt;/span&gt;&lt;span class="p"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;tensorflow_pkg&lt;/span&gt;&lt;span class="p"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;-&amp;lt;&lt;/span&gt;&lt;span class="nx"&gt;blah&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="bp"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;whl&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;where &lt;blah&gt; is some long version string. Just tab-complete it &amp;#8212; this should be the only .whl file in that directory&amp;nbsp;anyway.&lt;/p&gt;
&lt;p&gt;Now we can test it works! But before that, and &lt;strong&gt;this is important&lt;/strong&gt;, cd out of the tensorflow directory to somewhere completely different, e.g. your home directory. If you don&amp;#8217;t do this, when you try to import the package, Python will try to import it from the local directory and not the installed library, and fail with a cryptic error. This confused me the first&amp;nbsp;time.&lt;/p&gt;
&lt;p&gt;Anyway, to test it&amp;#8217;s installed &lt;span class="caps"&gt;OK&lt;/span&gt;, run python or ipython,&amp;nbsp;and:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt; &lt;span class="n"&gt;as&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;
&lt;span class="n"&gt;hello&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;Hello&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;TensorFlow&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;sess&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Session&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sess&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hello&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If this prints a message with no errors, you&amp;#8217;re good to&amp;nbsp;go.&lt;/p&gt;
&lt;p&gt;And we&amp;#8217;re done! I didn&amp;#8217;t do any specific speed comparisons but training and evaluating toy models was noticeably faster with the custom build than it had been before. Of course, some of this may be down to the Docker virtualization overhead, not just the &lt;span class="caps"&gt;CPU&lt;/span&gt; flags, but a win&amp;#8217;s a win &amp;#8212; and you save a load of memory by not using Docker&amp;nbsp;too.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andrew Clegg</dc:creator><pubDate>Sun, 28 May 2017 00:00:00 +0100</pubDate><guid>tag:www.andrewclegg.org,2017-05-28:tech/TensorFlowLaptopCPU.html</guid><category>tensorflow</category><category>machine learning</category><category>deep learning</category><category>osx</category><category>macos</category><category>mac</category></item><item><title>Interview with a Data Scientist</title><link>http://www.andrewclegg.org/news/PeadarCoyleInterview.html</link><description>&lt;p&gt;&lt;em&gt;I was recently interviewed by Peadar Coyle for his data science blog, &lt;a href="https://peadarcoyle.wordpress.com/"&gt;Models are Illuminating and Wrong&lt;/a&gt;, as the latest in a series of features on people in the field. It&amp;#8217;s archived here for posterity, but I would recommend taking a look at the &lt;a href="https://peadarcoyle.wordpress.com/2015/05/14/interviews-with-data-scientists-the-collection/"&gt;whole collection&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. What project have you worked on do you wish you could go back to, and do&amp;nbsp;better?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The one that most springs to mind was an analytics and visualization platform called Palomino that my team at Pearson built: a custom &lt;span class="caps"&gt;JS&lt;/span&gt;/&lt;span class="caps"&gt;HTML5&lt;/span&gt; app on top of Elasticsearch, Hadoop and HBase, plus a bunch of other pipeline components, some open source and some in-house. It kind of worked, and we learnt a lot, but it was buggy, flaky at the scale we tried to push it to, and reliant on constant supervision. And it&amp;#8217;s no longer in use, mostly for those&amp;nbsp;reasons.&lt;/p&gt;
&lt;p&gt;It was pretty ambitious to begin with, but I got dazzled by shiny new toys and the lure of realtime intelligence, and brought in too many new bits of tech that there was no organisational support for. We discovered that distributed data stores and message queues are &lt;em&gt;never&lt;/em&gt; as robust as they claim (c.f. &lt;a href="https://aphyr.com/tags/jepsen"&gt;Jepsen&lt;/a&gt;); that most people don&amp;#8217;t really need realtime interactive analytics; and that supporting complex clustered applications (even internal ones) is really hard, especially in an organisation that doesn&amp;#8217;t really have a devops&amp;nbsp;culture.&lt;/p&gt;
&lt;p&gt;These days, I&amp;#8217;d try very hard to find a solution using existing tools &amp;#8212; &lt;a href="https://www.elastic.co/products/kibana"&gt;Kibana&lt;/a&gt; for example looks much more mature and powerful than it did when we started out, and has a whole community and coherent ecosystem around it. And I&amp;#8217;d definitely shoot for a much simpler architecture with fewer moving parts and unfamiliar components. Dan McKinley&amp;#8217;s article &lt;a href="http://mcfunley.com/choose-boring-technology"&gt;Choose Boring Technology&lt;/a&gt; is very relevant&amp;nbsp;here.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. What advice do you have to younger analytics professionals and in particular PhD students in the&amp;nbsp;Sciences?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I was asked this the other day by a recent PhD grad who was interested in a data science career, so I&amp;#8217;ll pass on what I told&amp;nbsp;him.&lt;/p&gt;
&lt;p&gt;I think there are broadly three kinds of work that take place under the general heading of &amp;#8220;data scientist&amp;#8221;, although, there are also plenty of exceptions to&amp;nbsp;this.&lt;/p&gt;
&lt;p&gt;The first is about turning data into business insight, via statistical modelling, forecasting, predictive analytics, customer segmentation and clustering, survival analysis, churn prediction, visualization, online experiment design, and selection or design of meaningful metrics and&amp;nbsp;KPIs.&lt;/p&gt;
&lt;p&gt;The second is about developing data-driven products and features for the web, e.g. recommendation engines, trend detectors, anomaly detectors, search and ranking engines, ad placement algorithms, spam and abuse classifiers, content fingerprinting and similarity scoring,&amp;nbsp;etc.&lt;/p&gt;
&lt;p&gt;The third is really a more modern take on what used to be called operational research, i.e. optimizing business processes algorithmically to reduce time or cost, or increase coverage or reported&amp;nbsp;satisfaction.&lt;/p&gt;
&lt;p&gt;In many companies these will be separate roles, and not all companies do all three. But you&amp;#8217;ll also see roles that involve two or occasionally all three of these, in varying proportions. I guess a good start is to think about which appeals to you the most, and that will help guide&amp;nbsp;you.&lt;/p&gt;
&lt;p&gt;Don&amp;#8217;t get confused by the nomenclature: &amp;#8220;data scientist&amp;#8221; could mean any of those things, or something else entirely that&amp;#8217;s been rebranded to look cool. And you could be doing any of those things and not be called a data scientist. Read the job specs closely and ask lots of&amp;nbsp;questions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. What do you wish you knew earlier about being a data&amp;nbsp;scientist?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Well, I wish I&amp;#8217;d taken double maths for A level, all those years ago! As it was, I took the single option, and chose the mechanics module over statistics, something that held me back ever since despite various post-graduate courses. There are certain things that are just harder to crowbar into an adult brain, if you don&amp;#8217;t internalize the concepts early enough. I think languages and music are in that category&amp;nbsp;too.&lt;/p&gt;
&lt;p&gt;(For our global readers: A-levels are the qualifications from the last two years of high school. You usually do three or four subjects, or at least you did in my day. You could do standard maths with mechanics or stats, or standard + further with both, which counted as two&amp;nbsp;qualifications.)&lt;/p&gt;
&lt;p&gt;I had a similar experience with biology &amp;#8212; I dropped it when I was 16 but ended up working in bioinformatics for several years. Statistics and biology are both subjects that are much more interesting than school makes them seem, and I wish I&amp;#8217;d known that at the&amp;nbsp;time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4. How do you respond when you hear the phrase &amp;#8216;big&amp;nbsp;data&amp;#8217;?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Well, I used to react with anger and contempt, and have given some &lt;a href="https://drive.google.com/file/d/0B1HztRme3ZjZZjA1WHFJY25lQnM/view"&gt;pretty opinionated talks&lt;/a&gt; on that subject before. It&amp;#8217;s one of those things you can&amp;#8217;t get away from in the enterprise &lt;span class="caps"&gt;IT&lt;/span&gt; world, but ironically, since I joined Etsy I&amp;#8217;ve been numbed to the phrase by over-exposure&amp;#8230; Just because the Github repo for our Scalding and Cascading code is called&amp;nbsp;&amp;#8220;BigData&amp;#8221;.&lt;/p&gt;
&lt;p&gt;It&amp;#8217;s a marketing term with very little information content &amp;#8212; rather like &amp;#8220;cloud&amp;#8221;. But unlike &amp;#8220;cloud&amp;#8221; I actually think it&amp;#8217;s actively misleading &amp;#8212; it focuses attention on the size aspect, when most organisations have interesting and potentially valuable datasets that can fit on a laptop, or at least a medium-sized server. For that matter, a server with a &lt;em&gt;terabyte&lt;/em&gt; of &lt;span class="caps"&gt;RAM&lt;/span&gt; isn&amp;#8217;t much over $20K these days. &amp;#8220;Big data&amp;#8221; makes &lt;span class="caps"&gt;IT&lt;/span&gt; departments go all weak-kneed with delight or terror at the prospect of getting a Hadoop (or Spark) cluster, even though that&amp;#8217;s often not the right fit at&amp;nbsp;all.&lt;/p&gt;
&lt;p&gt;And as a noun phrase, it sucks, as it really doesn&amp;#8217;t refer to anything. You can&amp;#8217;t say &amp;#8220;we solved this problem with big data&amp;#8221; as big data isn&amp;#8217;t really a thing with any consistent&amp;nbsp;definition.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5. What is the most exciting thing about your&amp;nbsp;field?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;That&amp;#8217;s an interesting one. Deep learning is huge right now, but part of me still suspects it&amp;#8217;s a passing fad, partly because I&amp;#8217;m old enough to remember when plain-old neural networks were at the same stage of the hype cycle. Then they fell by the wayside for years. That said, the concrete improvements shown by convolutional nets on image recognition tasks are pretty&amp;nbsp;impressive.&lt;/p&gt;
&lt;p&gt;Time will tell whether that feat can be replicated in other domains. Recent work on &lt;a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/"&gt;recurrent nets for modelling sequences&lt;/a&gt; (text, music, etc.) is interesting, and there&amp;#8217;s been some fascinating work from Google (and their acquihires DeepMind) on learning to &lt;a href="http://arxiv.org/abs/1312.5602"&gt;play video games&lt;/a&gt; or &lt;a href="http://arxiv.org/abs/1410.4615"&gt;parse and execute code&lt;/a&gt;. These last two examples both combine deep learning with non-standard training methods (reinforcement learning and curriculum learning respectively), and my money&amp;#8217;s on this being the direction that will really shake things up. But I&amp;#8217;m a layman as far as this stuff&amp;nbsp;goes.&lt;/p&gt;
&lt;p&gt;One problem with neural architectures is that they&amp;#8217;re often black boxes, or at least pretty dark grey &amp;#8212; hard to interpret or gain much insight from. There are still a lot of huge domains where this is a hard sell, education and healthcare being good examples. Maybe someone will invent a learning method with the transparency of decision trees but the power of deep nets, and win over those people in jobs where &amp;#8220;just trust the machine&amp;#8221; doesn&amp;#8217;t&amp;nbsp;work.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6. How do you go about framing a data problem - in particular, how do you avoid spending too long, how do you manage expectations etc. How do you know what is good&amp;nbsp;enough?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It took me a long time to realise this, but short release cycles with small iterative improvements are the way to go. &lt;em&gt;Any&lt;/em&gt; result that shows an improvement over your current baseline is a result &amp;#8212; so even if you think there are much bigger wins to be had, get it into production, and test it on real data, while you work on its replacement. (Or if you&amp;#8217;re in academia, get a quick workshop paper out while you work on its&amp;nbsp;replacement!)&lt;/p&gt;
&lt;p&gt;This is also a great way to avoid overfitting, especially if you are in industry, or a service-driven academic field like bioinformatics. Instead of constantly bashing away at the error rate on a well-worn standard test set, get some new data from actual users (or cultures or sensors or whatever) and see if your model holds up in real life. And make sure you&amp;#8217;re optimizing for the right thing &amp;#8212; i.e. that your evaluation metrics really reflect the true cost of a&amp;nbsp;misprediction.&lt;/p&gt;
&lt;p&gt;I worked in natural language processing for quite a while, and I&amp;#8217;m sure that field was held back for a while by collective, cultural overfitting to the same-old datasets, like Penn Treebank section 23. There&amp;#8217;s an &lt;a href="http://hunch.net/?p=22"&gt;old John Langford article&lt;/a&gt; about this and other non-obvious ways to overfit, which is always worth a&amp;nbsp;re-read.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href="https://peadarcoyle.wordpress.com/2015/06/06/interview-with-a-data-scientist-andrew-clegg/"&gt;Original version at Peadar&amp;#8217;s&amp;nbsp;blog&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andrew Clegg</dc:creator><pubDate>Sat, 06 Jun 2015 00:00:00 +0100</pubDate><guid>tag:www.andrewclegg.org,2015-06-06:news/PeadarCoyleInterview.html</guid><category>interviews</category><category>data science</category></item><item><title>Kale: timeseries data mining at Etsy</title><link>http://www.andrewclegg.org/tech/KaleTalk.html</link><description>&lt;p&gt;&lt;em&gt;I&amp;#8217;m very pleased to announce that my talk proposal on &lt;a href="https://codeascraft.com/2013/06/11/introducing-kale/"&gt;Kale&lt;/a&gt; v2 has been accepted by both &lt;a href="http://monitorama.com/index.html"&gt;Monitorama 2015&lt;/a&gt; and &lt;a href="http://berlinbuzzwords.de/"&gt;Berlin Buzzwords 2015&lt;/a&gt;. Here&amp;#8217;s the&amp;nbsp;abstract.&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;Signatures, patterns and trends: Timeseries data mining at&amp;nbsp;Etsy&lt;/h4&gt;
&lt;p&gt;Etsy loves metrics. Everything that happens in our data centres gets recorded, graphed and stored. But with over a million metrics flowing in constantly, it’s hard for any team to keep on top of all that information. Graphing everything doesn’t scale, and traditional alerting methods based on thresholds become very prone to false&amp;nbsp;positives.&lt;/p&gt;
&lt;p&gt;That’s why we started Kale, an open-source software suite for pattern mining and anomaly detection in operational data streams. These are big topics with decades of research, but many of the methods in the literature are ineffective on terabytes of noisy data with unusual statistical characteristics, and techniques that require extensive manual analysis are unsuitable when your ops teams have service levels to&amp;nbsp;maintain.&lt;/p&gt;
&lt;p&gt;In this talk I’ll briefly cover the main challenges that traditional statistical methods face in this environment, and introduce some pragmatic alternatives that scale well and are easy to implement (and automate) on Elasticsearch and similar platforms. I’ll talk about the stumbling blocks we encountered with the first release of Kale, and the resulting architectural changes coming in version 2.0. And I’ll go into a little technical detail on the fingerprinting algorithms we use for fast approximate querying of metrics and their associated statistical metadata. These techniques have applications in clustering, outlier detection, similarity search and supervised learning, and they are not limited to the data centre but can be applied to any high-volume timeseries&amp;nbsp;data.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If you can&amp;#8217;t make it to either of these, videos will hopefully be available online soon&amp;nbsp;afterwards.&lt;/em&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andrew Clegg</dc:creator><pubDate>Sat, 21 Feb 2015 00:00:00 +0000</pubDate><guid>tag:www.andrewclegg.org,2015-02-21:tech/KaleTalk.html</guid><category>kale</category><category>monitoring</category><category>alerting</category><category>metrics</category><category>anomaly detection</category><category>devops</category><category>talks</category></item><item><title>You sure don’t look like a scientist</title><link>http://www.andrewclegg.org/culture/YouSureDontLookLikeAScientist.html</link><description>&lt;p&gt;You get a little tired of people asking what you do, when the answer&amp;#8217;s &amp;#8220;computational linguistics research in a bioinformatics group at the Institute for Structural Molecular Biology.&amp;#8221; There are enough unfamiliar terms in there to derail a light social conversation several times over, especially when you don&amp;#8217;t usually enjoy talking about work at parties. So I got into the habit of saying &amp;#8220;I&amp;#8217;m a scientist&amp;#8221; and glossing over the details unless people were&amp;nbsp;interested.&lt;/p&gt;
&lt;p&gt;The reactions from laypeople tend to run the whole gamut from intrigue to wariness and even, back in the days, occasionally outright hostility. Ten years ago, the 90s &amp;#8220;Frankenscience&amp;#8221; narrative was still lingering around, and the popular images associated with bioscience included &lt;span class="caps"&gt;GM&lt;/span&gt; crop protests, ears grown on mice, Dolly the sheep, and the horrific undercover pics from Huntingdon Life Sciences that the &lt;span class="caps"&gt;ALF&lt;/span&gt; put on every high street. Sometimes even fellow academics I met from arts and humanities departments would totally change their demeanour when they heard a trigger word like &amp;#8220;lab.&amp;#8221; I always felt particularly disappointed when that&amp;nbsp;happened.&lt;/p&gt;
&lt;p&gt;Another pretty common response was &amp;#8220;Really? You don&amp;#8217;t look like a scientist.&amp;#8221; Now this usually just amused and exasperated me in roughly equal measures &amp;#8212; and still does occasionally. But one time it nearly got me&amp;nbsp;deported.&lt;/p&gt;
&lt;h4&gt;Boston&amp;nbsp;manners&lt;/h4&gt;
&lt;p&gt;It&amp;#8217;s 2004, and I&amp;#8217;m arriving in Boston for &lt;a href="http://www1.cs.columbia.edu/~pablo/hlt-naacl04/"&gt;&lt;span class="caps"&gt;HLT&lt;/span&gt;-&lt;span class="caps"&gt;NAACL&lt;/span&gt;&amp;#8216;04&lt;/a&gt;. I&amp;#8217;m in the first year of my PhD, going to my first international conference &amp;#8212; and my first trip outside Europe for any reason. It&amp;#8217;s the height of summer, and I&amp;#8217;m in combat shorts and a sleeveless t-shirt as usual. I get to the front of the immigration queue and hand over my documents. &amp;#8220;Business or vacation?&amp;#8221; asks the border&amp;nbsp;guard.&lt;/p&gt;
&lt;p&gt;Neither really, I think to myself. &amp;#8220;I&amp;#8217;m going to an academic conference,&amp;#8221; I say instead, and give its full name. &amp;#8220;I&amp;#8217;m a PhD&amp;nbsp;student.&amp;#8221;&lt;/p&gt;
&lt;p&gt;This wasn&amp;#8217;t in the script. She stops pecking at her keyboard, squints at me over her glasses and chews this over for a moment. &amp;#8220;You&amp;#8217;re a &lt;em&gt;scientist&lt;/em&gt;?&amp;#8221; Nod. &amp;#8220;You coulda fooled me. You sure don&amp;#8217;t look like a&amp;nbsp;scientist.&amp;#8221;&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m a bit floored by this &amp;#8212; particularly as there&amp;#8217;s an unsettling mix of contempt and distrust creeping into her voice. I can&amp;#8217;t think of anything to say that isn&amp;#8217;t hazardously sarcastic, so I wave the conference details printout at her. She glances at it, not really interested, and calls over a colleague. &amp;#8220;This guy says he&amp;#8217;s a scientist, huh. Going to a&amp;nbsp;conference.&amp;#8221;&lt;/p&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Oh really?&amp;#8221; chuckles the guy. &amp;#8220;Whereabouts?&amp;#8221; The Park Plaza. He laughs a bit more. &amp;#8220;They won&amp;#8217;t even let you &lt;em&gt;in&lt;/em&gt; the Park Plaza looking like that! Now please come with&amp;nbsp;me.&amp;#8221;&lt;/p&gt;
&lt;p&gt;So he leads me to an inspection booth, and somewhere along the way, acquires another goon with a very large sniffer&amp;nbsp;dog.&lt;/p&gt;
&lt;h4&gt;Waive goodbye to your&amp;nbsp;rights&lt;/h4&gt;
&lt;p&gt;By now I&amp;#8217;m starting to get seriously worried. Why the disbelief? I&amp;#8217;m in my work clothes. I&amp;#8217;ve got a slightly punky haircut and a couple of tattoos visible, but nothing you wouldn&amp;#8217;t see in London every day. And this is Massachusetts, not Arkansas,&amp;nbsp;right?&lt;/p&gt;
&lt;p&gt;But more importantly &amp;#8212; I&amp;#8217;m travelling on a visa waiver form. This gives you exactly &lt;strong&gt;no rights whatsoever&lt;/strong&gt;. You can be summarily deported even if your papers are entirely in order, with no means of appeal. And I have absolutely no idea what happens then. Do they pay for your flight home? Or are you detained until you can arrange a ticket? As a student I have no spare funds to draw on, my parents are on holiday, and my girlfriend (now wife) is delerious with the &amp;#8216;flu at&amp;nbsp;home.&lt;/p&gt;
&lt;p&gt;And a deportation makes it very hard to ever get into the &lt;span class="caps"&gt;USA&lt;/span&gt; again. With the American authorities still in over-compensation mode post-11/9, there&amp;#8217;s a very real chance my academic career could get hobbled here, before it&amp;#8217;s even&amp;nbsp;started.&lt;/p&gt;
&lt;p&gt;I almost hit panic level when Laughing Guy snaps on the rubber gloves, but it&amp;#8217;s just to rifle through my bag. Meanwhile Dog Dude is going &amp;#8220;Find it! Find it! Find it!&amp;#8221; and his hound is all over me. British sniffer dogs tend to be small friendly beagles or similar &amp;#8212; cute and floppy-eared &amp;#8212; not this Rottweiler-sized beast. (Bit vague on breeds I&amp;#8217;m afraid &amp;#8212; not a dog&amp;nbsp;person.)&lt;/p&gt;
&lt;p&gt;And then just like that, it&amp;#8217;s over. They don&amp;#8217;t phone the conference or my college for confirmation, as I suggest. But suddenly my suspicious credentials are just fine. They don&amp;#8217;t even search me all that thoroughly, which is obviously a blessing, but makes me wonder if they actually expected to find anything, or just wanted to put me in my place. Welcome to&amp;nbsp;America.&lt;/p&gt;
&lt;h4&gt;Bio&amp;nbsp;diversity&lt;/h4&gt;
&lt;p&gt;From talking to friends and colleagues at the time, and &lt;a href="https://twitter.com/AstroKatie/status/520838801006936066"&gt;discussions online&lt;/a&gt; more recently, &amp;#8220;you don&amp;#8217;t look like a scientist&amp;#8221; is a pretty common reaction. I&amp;#8217;d hope it&amp;#8217;s much less common today, with the likes of Ben Goldacre, Simon Singh, Alice Roberts, Jim Al-Khalili and of course Brian Cox putting a more realistic face on science in the media, and I&amp;#8217;d &lt;em&gt;really&lt;/em&gt; hope the consequences of that reaction are typically much less extreme than my&amp;nbsp;story.&lt;/p&gt;
&lt;p&gt;But there&amp;#8217;s still a long way to go. Women scientists are still under-represented in the media, and our most prominent and influential is frankly &lt;a href="http://www.theguardian.com/science/head-quarters/2014/oct/03/susan-greenfield-mind-change-technology-evidence"&gt;turning out to be a bit of a crank&lt;/a&gt;. Dawkins has retired from his Public Understanding of Science post in order to pursue his hobby of Public Misrepresentation of Science full-time, which isn&amp;#8217;t doing anyone any favours. Of course, this is very much a &lt;span class="caps"&gt;UK&lt;/span&gt;-centric view, and without the &lt;span class="caps"&gt;BBC&lt;/span&gt; and the Guardian things would look a lot less&amp;nbsp;encouraging.&lt;/p&gt;
&lt;p&gt;And let&amp;#8217;s not forget that presence of visible role models and a more welcoming atmosphere for younger scientists won&amp;#8217;t necessarily equate to better career prospects. &lt;a href="http://www.timeshighereducation.co.uk/news/chuka-umunna-pledges-action-on-lack-of-black-professors/2016295.article#.VDuf8ztJt6s.twitter"&gt;Recent &lt;span class="caps"&gt;UK&lt;/span&gt; figures&lt;/a&gt; show that only 22% of professors are women and &lt;em&gt;less than half a percent&lt;/em&gt; are black. These numbers are across all subjects but I doubt sciences fair any better than&amp;nbsp;others.&lt;/p&gt;
&lt;p&gt;I have no idea what the picture&amp;#8217;s like in the States, but I haven&amp;#8217;t been detained there recently, so maybe there&amp;#8217;s hope&amp;nbsp;yet.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Updated 2014-10-13 to add new figures from &lt;span class="caps"&gt;THE&lt;/span&gt;&amp;nbsp;article&lt;/em&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andrew Clegg</dc:creator><pubDate>Sun, 12 Oct 2014 00:00:00 +0100</pubDate><guid>tag:www.andrewclegg.org,2014-10-12:culture/YouSureDontLookLikeAScientist.html</guid><category>science</category><category>travel</category><category>media</category><category>equality</category></item><item><title>The unwisdom of the crowd: marketing, metrics &amp; machine learning</title><link>http://www.andrewclegg.org/data/UnwisdomOfTheCrowd.html</link><description>&lt;h4&gt;Or, why Google Analytics is not a good analytics&amp;nbsp;tool.&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;This is a slightly modified repost of an article I wrote for an internal Pearson blog recently. My colleague &lt;a href="https://twitter.com/tendayiviki"&gt;Tendayi&lt;/a&gt; encouraged me to post it here, so it could reach a wider&amp;nbsp;audience.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Vanity metrics&amp;#8221; is a phrase I&amp;#8217;ve heard cropping up a few times recently, in the context of growth engineering, the lean startup movement, and discussions around product lifecycles. It&amp;#8217;s hard to find any agreement on what metrics are vanity metrics, but in general it seems to refer to metrics that product owners measure and report in order to boast about growth, but which don&amp;#8217;t themselves prove anything about value or guide decision-making. Numbers of logins, of resources viewed, of content items downloaded, or of messages sent &amp;mdash; these might be considered vanity metrics, depending on the product. This seemed a bit strange to me, because in my world, all these metrics are extremely&amp;nbsp;valuable.&lt;/p&gt;
&lt;p&gt;Suddenly it occurred to me this morning: when product and marketing experts talk about these metrics, they&amp;#8217;re almost always referring to &lt;em&gt;aggregates&lt;/em&gt; &amp;mdash; counts or averages across all users, or specific predefined segments. But when data scientists talk about them, we&amp;#8217;re often talking about &lt;em&gt;individual users&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;So why would I want to record and measure login counts or download counts for individual users? Or in the education domain, where I work: why count learning resources viewed, time taken on tasks, etc.? Well, all of these things are essential components of a user profile, and without a good user profile, you can&amp;#8217;t do things&amp;nbsp;like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Predict&lt;/strong&gt; which users will suffer poor educational outcomes&lt;ul&gt;
&lt;li&gt;Contact those with poor predicted outcomes, to offer them more&amp;nbsp;support&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Recommend&lt;/strong&gt; content to users&lt;ul&gt;
&lt;li&gt;Educational tasks that are likely to improve their assessment&amp;nbsp;scores&lt;/li&gt;
&lt;li&gt;Purchases they&amp;#8217;re likely to&amp;nbsp;make&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Score&lt;/strong&gt; users for loyalty&lt;ul&gt;
&lt;li&gt;Target low-scoring users in order to reduce&amp;nbsp;churn&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Estimate&lt;/strong&gt; the probability of a given user responding to an offer&lt;ul&gt;
&lt;li&gt;Tailor offers to specific users in order to lift acceptance rate or overall&amp;nbsp;revenue&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Explain&lt;/strong&gt; negative trends in the behaviour of certain users&lt;ul&gt;
&lt;li&gt;Substandard educational&amp;nbsp;outcomes&lt;/li&gt;
&lt;li&gt;Failure to renew&amp;nbsp;subscriptions&lt;/li&gt;
&lt;li&gt;Low click-through rate on&amp;nbsp;recommendations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&amp;#8230; and so&amp;nbsp;on.&lt;/p&gt;
&lt;p&gt;Some of these examples are specific to our area of business, and I&amp;#8217;m sure you have similar domain-specific challenges, but others apply across the commercial web. And all of them need activity data down to the level of individual users. Something that may seem like a &amp;#8220;vanity metric&amp;#8221; when reported across all users &amp;mdash; number of logins per week, for example &amp;mdash; can be a very important indicator of an &lt;em&gt;individual&lt;/em&gt; user&amp;#8217;s engagement, when it&amp;#8217;s fed into a machine learning model for risk&amp;nbsp;scoring.&lt;/p&gt;
&lt;p&gt;At the top of this article I mentioned Google Analytics. I don&amp;#8217;t want to pick on &lt;span class="caps"&gt;GA&lt;/span&gt; specifically, as this is common across web analytics tools in general, but I sometimes hear product owners saying &amp;#8220;we don&amp;#8217;t need a way to record user activity, we have Google Analytics already.&amp;#8221; But this misses the point that &lt;span class="caps"&gt;GA&lt;/span&gt; is designed to report aggregates across all your users, or across segments that you&amp;#8217;ve defined in advance. Unless it&amp;#8217;s changed considerably since I last used it, &lt;span class="caps"&gt;GA&lt;/span&gt; makes it very hard or impossible to report these metrics for individual users, or for &lt;em&gt;retrospectively-defined&lt;/em&gt; groups of users that are interesting because of some shared (usually negative) behaviour. And it also makes it hard or impossible to connect the activity of individual users with other elements of a user profile, such as demographic information, educational records, purchase history and so&amp;nbsp;on.&lt;/p&gt;
&lt;p&gt;So please take the term &amp;#8220;vanity metrics&amp;#8221; with a pinch of salt. A particular &lt;span class="caps"&gt;KPI&lt;/span&gt; may be worth very little when reported at the level of your entire user base, but it might be the differentiator between a loyal customer or satisfied learner, a borderline case who needs help and support right now, or a lost&amp;nbsp;cause.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andrew Clegg</dc:creator><pubDate>Mon, 16 Jun 2014 00:00:00 +0100</pubDate><guid>tag:www.andrewclegg.org,2014-06-16:data/UnwisdomOfTheCrowd.html</guid><category>analytics</category><category>data science</category><category>product development</category><category>marketing</category></item><item><title>All your Bayes are belong to us! PyMC, PyStan and emcee in Snake Charmer</title><link>http://www.andrewclegg.org/tech/AllYourBayes.html</link><description>&lt;p&gt;&lt;a href="https://github.com/pymc-devs/pymc"&gt;PyMC&lt;/a&gt; is the most widely-used Python package for Bayesian modelling, learning and inference, but it isn&amp;#8217;t the only choice, by far. &lt;a href="https://twitter.com/jakevdp"&gt;Jake Vanderplas&lt;/a&gt; recently posted a pretty detailed comparison of PyMC, &lt;a href="http://mc-stan.org/"&gt;PyStan&lt;/a&gt; and &lt;a href="http://dan.iel.fm/emcee/current/"&gt;emcee&lt;/a&gt; on &lt;a href="http://jakevdp.github.io/blog/2014/06/14/frequentism-and-bayesianism-4-bayesian-in-python/"&gt;his blog&lt;/a&gt;, and even if you&amp;#8217;re not an expert in Bayesian methods (I&amp;#8217;m certainly not) I&amp;#8217;d recommend you give it a read. It walks you through the same task in all three packages in order to get a feel for how they work, which is a great way to do&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;As well as functionality, speed and accuracy, Jake also covered installation, and mentioned that PyStan can be painful to install, especially if you don&amp;#8217;t already have a full C/C++ toolset. While many Linux users do, these days a lot of Mac users don&amp;#8217;t, and I&amp;#8217;d hazard a guess that &lt;em&gt;most&lt;/em&gt; Windows users don&amp;#8217;t, even if they program in other languages frequently. Many Python packages need to compile native code during installation, but some of them get round this by offering binaries for various platforms &amp;#8212; although this often not a foolproof solution either. But PyStan also uses the compiler at &lt;em&gt;runtime&lt;/em&gt;, in the process of translating its own model definition language into machine code, so I guess there&amp;#8217;s no easy way for them to build a one-click&amp;nbsp;installer.&lt;/p&gt;
&lt;p&gt;This is exactly the kind of reason why I started &lt;a href="https://github.com/andrewclegg/snake-charmer"&gt;Snake Charmer&lt;/a&gt; in the first place. Installing it and getting the tests passing on Snake Charmer&amp;#8217;s Ubuntu &lt;span class="caps"&gt;VM&lt;/span&gt; was &amp;#8212; well not entirely trivial, but an hour or two at the very most. And once it works for me, it works for everyone. You&amp;#8217;ll now get PyStan and the slightly less fiddly emcee as standard with every Snake Charmer &lt;span class="caps"&gt;VM&lt;/span&gt; &amp;#8212; so, err, forget your unpleasant prior experiences and raise your expectations.&amp;nbsp;(Sorry&amp;#8230;)&lt;/p&gt;
&lt;p&gt;I think this makes Snake Charmer the first Python distribution to include all three of these&amp;nbsp;tools.&lt;/p&gt;
&lt;p&gt;One last note: if you try to reproduce Jake&amp;#8217;s tutorial in Snake Charmer, you may notice some differences. He uses PyMC 2 but Snake Charmer&amp;#8217;s on a pre-release of version 3 already. (Given limited time to work on this, I&amp;#8217;d rather stay ahead of the game&amp;#8230;) However, here&amp;#8217;s a &lt;a href="http://jakevdp.github.io/blog/2014/06/14/frequentism-and-bayesianism-4-bayesian-in-python/#comment-1436231209"&gt;note from Thomas Wiecki&lt;/a&gt; showing the equivalent steps in PyMC&amp;nbsp;3.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andrew Clegg</dc:creator><pubDate>Wed, 04 Jun 2014 00:00:00 +0100</pubDate><guid>tag:www.andrewclegg.org,2014-06-04:tech/AllYourBayes.html</guid><category>snake charmer</category><category>bayes</category><category>bayesian</category><category>python</category><category>statistics</category><category>machine learning</category></item><item><title>Lyric clouds, genre maps and distinctive words</title><link>http://www.andrewclegg.org/data/LyricClouds.html</link><description>&lt;p&gt;&lt;em&gt;This is a repost of an &lt;a href="http://blog.last.fm/2011/06/22/lyric-clouds-genre-maps-and-distinctive-words"&gt;article&lt;/a&gt; I wrote for the Last.fm blog while working there in 2011. The images disappeared from Last.fm so I&amp;#8217;m serving them out of the wonderful &lt;a href="http://web.archive.org"&gt;Internet Archive&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;One of the interesting things that sets even superficially similiar genres of music apart is their lyrical content. Last.fm tags can overlap to a great degree, but we were interested to see what the words can tell you about the subtler shades of meaning that go along with those tags. As usual around here, the best way to answer questions like these is by asking the&amp;nbsp;data.&lt;/p&gt;
&lt;p&gt;So I downloaded the &lt;a href="http://labrosa.ee.columbia.edu/millionsong/musixmatch"&gt;musiXmatch dataset&lt;/a&gt;, a collection of lyric tables for nearly 240,000 songs from all around the world (and the musical universe). They are tables in the sense that they don&amp;#8217;t contain the intact lyrics of each song, but rather a list of words present in each song, along with the number of times that word occurs. No use for karaoke, but perfect for investigating the overall properties of a genre. I then matched up the songs in the dataset with tracks in our own catalogue, and correlated this with Last.fm tag data, in order to count the number of times a given word appeared in each of several prominent&amp;nbsp;genres.&lt;/p&gt;
&lt;h4&gt;Lyric&amp;nbsp;clouds&lt;/h4&gt;
&lt;p&gt;Of course, lists of words and frequencies are a little dry, but thankfully &lt;span class="caps"&gt;IBM&lt;/span&gt; have released a &lt;a href="http://www.alphaworks.ibm.com/tech/wordcloud"&gt;Word-Cloud Generator&lt;/a&gt; which can take a weighted list of words and display it graphically, as seen on the &lt;a href="http://www.wordle.net/"&gt;Wordle&lt;/a&gt; website. The more often a word appears, the bigger it will be rendered. Here&amp;#8217;s what it came up with for the genres I tried — the software did the layout, but you can blame me for the font&amp;nbsp;selection.&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
&lt;table&gt;
    &lt;tbody&gt;&lt;tr&gt;
        &lt;td align="center" valign="middle" width="200"&gt;
            &lt;i&gt;Click to open full images in a new window.&lt;br&gt;&lt;br&gt;
                &lt;b&gt;Warning: they contain lyrics you may find offensive. Not safe for work.&lt;/b&gt;&lt;/i&gt;
        &lt;/td&gt;
        &lt;td align="center" valign="middle" width="200"&gt;
            &lt;a href="http://web.archive.org/web/20120107121411/http://users.last.fm/~andy/lyric_clouds/1/blues.png" target="wordle"&gt;
                &lt;img src="http://web.archive.org/web/20120107121411im_/http://users.last.fm/~andy/lyric_clouds/1/blues_thumb.png"&gt;&lt;br&gt;
Blues
            &lt;/a&gt;
        &lt;/td&gt;
        &lt;td align="center" valign="middle" width="200"&gt;
            &lt;a href="http://web.archive.org/web/20120107121411/http://users.last.fm/~andy/lyric_clouds/1/country.png" target="wordle"&gt;
                &lt;img src="http://web.archive.org/web/20120107121411im_/http://users.last.fm/~andy/lyric_clouds/1/country_thumb.png"&gt;&lt;br&gt;
Country
            &lt;/a&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;&lt;td colspan="3"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;
        &lt;td align="center" valign="middle" width="200"&gt;
            &lt;a href="http://web.archive.org/web/20120107121411/http://users.last.fm/~andy/lyric_clouds/1/electronic.png" target="wordle"&gt;
                &lt;img src="http://web.archive.org/web/20120107121411im_/http://users.last.fm/~andy/lyric_clouds/1/electronic_thumb.png"&gt;&lt;br&gt;
Electronic
            &lt;/a&gt;
        &lt;/td&gt;
        &lt;td align="center" valign="middle" width="200"&gt;
            &lt;a href="http://web.archive.org/web/20120107121411/http://users.last.fm/~andy/lyric_clouds/1/folk.png" target="wordle"&gt;
                &lt;img src="http://web.archive.org/web/20120107121411im_/http://users.last.fm/~andy/lyric_clouds/1/folk_thumb.png"&gt;&lt;br&gt;
Folk
            &lt;/a&gt;
        &lt;/td&gt;
        &lt;td align="center" valign="middle" width="200"&gt;
            &lt;a href="http://web.archive.org/web/20120107121411/http://users.last.fm/~andy/lyric_clouds/1/goth.png" target="wordle"&gt;
                &lt;img src="http://web.archive.org/web/20120107121411im_/http://users.last.fm/~andy/lyric_clouds/1/goth_thumb.png"&gt;&lt;br&gt;
Goth
            &lt;/a&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;&lt;td colspan="3"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;
        &lt;td align="center" valign="middle" width="200"&gt;
            &lt;a href="http://web.archive.org/web/20120107121411/http://users.last.fm/~andy/lyric_clouds/1/hip-hop.png" target="wordle"&gt;
                &lt;img src="http://web.archive.org/web/20120107121411im_/http://users.last.fm/~andy/lyric_clouds/1/hip-hop_thumb.png"&gt;&lt;br&gt;
Hip-hop
            &lt;/a&gt;
        &lt;/td&gt;
        &lt;td align="center" valign="middle" width="200"&gt;
            &lt;a href="http://web.archive.org/web/20120107121411/http://users.last.fm/~andy/lyric_clouds/1/indie.png" target="wordle"&gt;
                &lt;img src="http://web.archive.org/web/20120107121411im_/http://users.last.fm/~andy/lyric_clouds/1/indie_thumb.png"&gt;&lt;br&gt;
Indie
            &lt;/a&gt;
        &lt;/td&gt;
        &lt;td align="center" valign="middle" width="200"&gt;
            &lt;a href="http://web.archive.org/web/20120107121411/http://users.last.fm/~andy/lyric_clouds/1/metal.png" target="wordle"&gt;
                &lt;img src="http://web.archive.org/web/20120107121411im_/http://users.last.fm/~andy/lyric_clouds/1/metal_thumb.png"&gt;&lt;br&gt;
Metal
            &lt;/a&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;&lt;td colspan="3"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;
        &lt;td align="center" valign="middle" width="200"&gt;
            &lt;a href="http://web.archive.org/web/20120107121411/http://users.last.fm/~andy/lyric_clouds/1/rap.png" target="wordle"&gt;
                &lt;img src="http://web.archive.org/web/20120107121411im_/http://users.last.fm/~andy/lyric_clouds/1/rap_thumb.png"&gt;&lt;br&gt;
Rap
            &lt;/a&gt;
        &lt;/td&gt;
        &lt;td align="center" valign="middle" width="200"&gt;
            &lt;a href="http://web.archive.org/web/20120107121411/http://users.last.fm/~andy/lyric_clouds/1/rock.png" target="wordle"&gt;
                &lt;img src="http://web.archive.org/web/20120107121411im_/http://users.last.fm/~andy/lyric_clouds/1/rock_thumb.png"&gt;&lt;br&gt;
Rock
            &lt;/a&gt;
        &lt;/td&gt;
        &lt;td align="center" valign="middle" width="200"&gt;
            &lt;a href="http://web.archive.org/web/20120107121411/http://users.last.fm/~andy/lyric_clouds/1/soul.png" target="wordle"&gt;
                &lt;img src="http://web.archive.org/web/20120107121411im_/http://users.last.fm/~andy/lyric_clouds/1/soul_thumb.png"&gt;&lt;br&gt;
Soul
            &lt;/a&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;I did a bit of pre-processing to remove common &amp;#8216;stopwords&amp;#8217; that don&amp;#8217;t really hold any information about the topics of the lyrics (and, for, I, you, the, plus many more), but this only took into account English words — and if you look closely, you&amp;#8217;ll see a few common words from German, French and Spanish (and probably others) that are from foreign-language songs in the dataset. But what&amp;#8217;s most striking for me about these is not how much they differ, but in fact how often some of the words appear prominently across genres. Almost everyone sings about love, for example, with the exception of Rap and Hip-Hop, and time comes up… time and time&amp;nbsp;again.&lt;/p&gt;
&lt;h4&gt;Genre&amp;nbsp;maps&lt;/h4&gt;
&lt;p&gt;A limitation of word clouds is that while they&amp;#8217;re great for showing the comparative popularity of words within a genre, they&amp;#8217;re not so good for looking at the overall similarities or differences of several genres at once. To do that, you need some measure of similarity which can be rendered graphically as a kind of &amp;#8216;genre neighbourhood map&amp;#8217;. So I measured the similarities between the word lists for each genre, ranked by popularity, using &lt;a href="http://blog.codalism.com/?p=1317"&gt;a method&lt;/a&gt; which was developed to compare the result rankings from different search engines. This gives a single value for how similar the lyric choices are between each pair of genres, where differences towards the top of the lists (the most popular words) are considered more important than differences further down. A bit of &lt;a href="http://www.statmethods.net/advstats/mds.html"&gt;extra number crunching&lt;/a&gt; in &lt;a href="http://www.r-project.org/"&gt;R&lt;/a&gt; can convert these similarity scores into a 2D map, which I imported into &lt;a href="http://www.openoffice.org/"&gt;OpenOffice&lt;/a&gt; to&amp;nbsp;render:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://web.archive.org/web/20120107121411/http://users.last.fm/~andy/lyric_clouds/lyric_map.png" target="wordle"&gt;&lt;br&gt;
&lt;img src="http://web.archive.org/web/20120107121411im_/http://users.last.fm/~andy/lyric_clouds/lyric_map_small.png"&gt;&lt;br&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Click image to open larger version in a new&amp;nbsp;window.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This map is really interesting for its combination of expected and unexpected neighbours, and also for the way it clearly shows Rap and Hip-Hop as outliers from the main axis on the left. Goth and Metal, which may appear similar to the un-trained ear (and eye!), are considerably separated, while Metal and Folk are — surprisingly — much closer. Electronic (a very broad tag) is clustered together with Soul and Blues, presumably because of the soulful origins of house music, which is one of the more lyrical electronic sub-genres. And Rap and Hip-Hop, which might be considered synonymous by the layman, are about as different as Indie and Country in terms of lyric&amp;nbsp;ranking.&lt;/p&gt;
&lt;h4&gt;Distinctive&amp;nbsp;words&lt;/h4&gt;
&lt;p&gt;The word clouds as shown draw the viewer&amp;#8217;s attention to the very frequent words, but these also tend to be the ones like love and time which are popular across genres. This is a problem if you want to find out which words are most distinctive or characteristic of a given genre — the words which, if used as search terms for example, would be best at selecting songs from that genre correctly (true positives), while minimizing the number of songs retrieved from other genres (false positives). Once again, information retrieval (the science behind search engines) can help us — the F measure or &lt;a href="http://en.wikipedia.org/wiki/F-score"&gt;F score&lt;/a&gt; is specifically designed for measuring the tradeoff between true positives and false positives in a set of results. It&amp;#8217;s a score between 0 and 1, where 0 means &amp;#8220;no relevant documents retrieved&amp;#8221;, but 1 means &amp;#8220;all relevant documents retrieved&amp;#8221; and &amp;#8220;no additional spurious documents&amp;nbsp;retrieved&amp;#8221;.&lt;/p&gt;
&lt;p&gt;So I calculated the F score that each word would have as a search term for each genre in some notional lyric-based search engine: &amp;#8220;how relevant would the results be if I searched for Indie tracks with the search term friend&amp;#8221; for example. This doesn&amp;#8217;t take into account the number of times each word occurs within a song, just the fact that it occurs at all, but it does let us redraw the lyric clouds with each word&amp;#8217;s size determined by its F score for that genre. As you can see, this brings out the words that are characteristic of each genre, rather than emphasizing those that are globally&amp;nbsp;popular:&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
&lt;table&gt;
    &lt;tbody&gt;&lt;tr&gt;
        &lt;td align="center" valign="middle" width="200"&gt;
            &lt;i&gt;Click to open full images in a new window.&lt;br&gt;&lt;br&gt;
                &lt;b&gt;Warning: they contain lyrics you may find offensive. Not safe for work.&lt;/b&gt;&lt;/i&gt;
        &lt;/td&gt;
        &lt;td align="center" valign="middle" width="200"&gt;
            &lt;a href="http://web.archive.org/web/20120107121411/http://users.last.fm/~andy/lyric_clouds/2/blues.png" target="wordle"&gt;
                &lt;img src="http://web.archive.org/web/20120107121411im_/http://users.last.fm/~andy/lyric_clouds/2/blues_thumb.png"&gt;&lt;br&gt;
Blues
            &lt;/a&gt;
        &lt;/td&gt;
        &lt;td align="center" valign="middle" width="200"&gt;
            &lt;a href="http://web.archive.org/web/20120107121411/http://users.last.fm/~andy/lyric_clouds/2/country.png" target="wordle"&gt;
                &lt;img src="http://web.archive.org/web/20120107121411im_/http://users.last.fm/~andy/lyric_clouds/2/country_thumb.png"&gt;&lt;br&gt;
Country
            &lt;/a&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;&lt;td colspan="3"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;
        &lt;td align="center" valign="middle" width="200"&gt;
            &lt;a href="http://web.archive.org/web/20120107121411/http://users.last.fm/~andy/lyric_clouds/2/electronic.png" target="wordle"&gt;
                &lt;img src="http://web.archive.org/web/20120107121411im_/http://users.last.fm/~andy/lyric_clouds/2/electronic_thumb.png"&gt;&lt;br&gt;
Electronic
            &lt;/a&gt;
        &lt;/td&gt;
        &lt;td align="center" valign="middle" width="200"&gt;
            &lt;a href="http://web.archive.org/web/20120107121411/http://users.last.fm/~andy/lyric_clouds/2/folk.png" target="wordle"&gt;
                &lt;img src="http://web.archive.org/web/20120107121411im_/http://users.last.fm/~andy/lyric_clouds/2/folk_thumb.png"&gt;&lt;br&gt;
Folk
            &lt;/a&gt;
        &lt;/td&gt;
        &lt;td align="center" valign="middle" width="200"&gt;
            &lt;a href="http://web.archive.org/web/20120107121411/http://users.last.fm/~andy/lyric_clouds/2/goth.png" target="wordle"&gt;
                &lt;img src="http://web.archive.org/web/20120107121411im_/http://users.last.fm/~andy/lyric_clouds/2/goth_thumb.png"&gt;&lt;br&gt;
Goth
            &lt;/a&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;&lt;td colspan="3"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;
        &lt;td align="center" valign="middle" width="200"&gt;
            &lt;a href="http://web.archive.org/web/20120107121411/http://users.last.fm/~andy/lyric_clouds/2/hip-hop.png" target="wordle"&gt;
                &lt;img src="http://web.archive.org/web/20120107121411im_/http://users.last.fm/~andy/lyric_clouds/2/hip-hop_thumb.png"&gt;&lt;br&gt;
Hip-hop
            &lt;/a&gt;
        &lt;/td&gt;
        &lt;td align="center" valign="middle" width="200"&gt;
            &lt;a href="http://web.archive.org/web/20120107121411/http://users.last.fm/~andy/lyric_clouds/2/indie.png" target="wordle"&gt;
                &lt;img src="http://web.archive.org/web/20120107121411im_/http://users.last.fm/~andy/lyric_clouds/2/indie_thumb.png"&gt;&lt;br&gt;
Indie
            &lt;/a&gt;
        &lt;/td&gt;
        &lt;td align="center" valign="middle" width="200"&gt;
            &lt;a href="http://web.archive.org/web/20120107121411/http://users.last.fm/~andy/lyric_clouds/2/metal.png" target="wordle"&gt;
                &lt;img src="http://web.archive.org/web/20120107121411im_/http://users.last.fm/~andy/lyric_clouds/2/metal_thumb.png"&gt;&lt;br&gt;
Metal
            &lt;/a&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;&lt;td colspan="3"&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;
        &lt;td align="center" valign="middle" width="200"&gt;
            &lt;a href="http://web.archive.org/web/20120107121411/http://users.last.fm/~andy/lyric_clouds/2/rap.png" target="wordle"&gt;
                &lt;img src="http://web.archive.org/web/20120107121411im_/http://users.last.fm/~andy/lyric_clouds/2/rap_thumb.png"&gt;&lt;br&gt;
Rap
            &lt;/a&gt;
        &lt;/td&gt;
        &lt;td align="center" valign="middle" width="200"&gt;
            &lt;a href="http://web.archive.org/web/20120107121411/http://users.last.fm/~andy/lyric_clouds/2/rock.png" target="wordle"&gt;
                &lt;img src="http://web.archive.org/web/20120107121411im_/http://users.last.fm/~andy/lyric_clouds/2/rock_thumb.png"&gt;&lt;br&gt;
Rock
            &lt;/a&gt;
        &lt;/td&gt;
        &lt;td align="center" valign="middle" width="200"&gt;
            &lt;a href="http://web.archive.org/web/20120107121411/http://users.last.fm/~andy/lyric_clouds/2/soul.png" target="wordle"&gt;
                &lt;img src="http://web.archive.org/web/20120107121411im_/http://users.last.fm/~andy/lyric_clouds/2/soul_thumb.png"&gt;&lt;br&gt;
Soul
            &lt;/a&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;I think they bring out the unique character of each genre much more effectively, and the variation in size between the words is much less, so the less prominent words are easier to see. There are some interesting quirks visible too. For example, many German words are much more clearly visible in the Goth cloud than they were before, reflecting both the comparatively large number of songs in German in that genre, and the lack of German lyrics in most other genres. Country for example is entirely&amp;nbsp;English.&lt;/p&gt;
&lt;p&gt;Finally, a little extra present from the data. The word with the highest F score in the whole dataset is Christmas, with an F score of 0.3892 for the tag… Christmas. So, unseasonal greetings from the data crunchers here at Last.&lt;span class="caps"&gt;HQ&lt;/span&gt;!&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Thanks to &lt;a href="http://musixmatch.com/"&gt;musiXmatch&lt;/a&gt; for making the lyric database available, and &lt;a href="http://www.columbia.edu/~tb2332/"&gt;Thierry Bertin-Mahieux&lt;/a&gt; for helping me to reconstruct the full words from the stems in the&amp;nbsp;database.&lt;/em&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andrew Clegg</dc:creator><pubDate>Wed, 04 Jun 2014 00:00:00 +0100</pubDate><guid>tag:www.andrewclegg.org,2014-06-04:data/LyricClouds.html</guid><category>music</category><category>lyrics</category><category>lastfm</category><category>IR</category><category>visualization</category></item><item><title>Snake Charmer: the all-in-one data science toolbox for Python 3</title><link>http://www.andrewclegg.org/tech/SnakeCharmerIntro.html</link><description>&lt;p&gt;Python&amp;#8217;s an amazing language, but it&amp;#8217;s constantly let down by its packaging and distribution infrastructure. Apologies to those people who&amp;#8217;ve worked hard to fix this, but it sucks. I&amp;#8217;ve wasted days in the past getting a particular set of packages to cooperate on a particular machine, only to find that the resulting combination of library files, symlinks, chicken blood and chanting doesn&amp;#8217;t work on any &lt;em&gt;other&lt;/em&gt;&amp;nbsp;machines.&lt;/p&gt;
&lt;p&gt;The &lt;a href="http://virtualenv.readthedocs.org/en/latest/"&gt;virtualenv&lt;/a&gt; tool helps a bit, by letting you have entirely separate Pythons, different versions if necessary, with their own sandboxed libraries and tools. But not all packages behave well in virtualenvs. Some are just sloppily written, but others have very specific dependencies on libraries supplied by your operating system or compiler toolchain, which may be written in C or Fortran or Ancient Enochian, and can&amp;#8217;t easily be localized to a virtualenv. Some even have specific hardware requirements, or platform-specific behavioural&amp;nbsp;quirks.&lt;/p&gt;
&lt;p&gt;This is particularly true in scientific and statistical computing, where some of the most popular Python tools make use of low-level libraries for linear algebra or parallel computing, and others rely on &lt;span class="caps"&gt;OS&lt;/span&gt;-dependent features for image rendering or interprocess communication. And behavioural differences and incompatibilities can be particularly pernicious &amp;mdash; maybe your code will run without any errors, but quietly produce &lt;a href="https://github.com/statsmodels/statsmodels/issues/1690"&gt;slightly inaccurate predictions&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;Meanwhile, in&amp;nbsp;Shoreditch&amp;#8230;&lt;/h4&gt;
&lt;p&gt;Thankfully, there&amp;#8217;s a solution to many of these problems, if we borrow an idea from our much hipper web developer friends. These days it&amp;#8217;s quite common to build standardized, pre-packaged virtual machines (VMs) for developers to work in, meaning your code has the same runtime environment as all your teammates&amp;#8217; code does, and this closely resembles the servers you will eventually deploy to. By running a little server inside each developer&amp;#8217;s laptop or desktop, with its own &lt;span class="caps"&gt;OS&lt;/span&gt; and emulated &amp;#8216;hardware&amp;#8217;, you mask the differences between all those machines and the software installed on&amp;nbsp;them.&lt;/p&gt;
&lt;p&gt;Who cares if Alice has Mountain Lion on a MacBook Air, and Bob has Lucid Lynx on a water-cooled tower &lt;span class="caps"&gt;PC&lt;/span&gt; with a Cylon-themed case mod? When they&amp;#8217;re building code and running tests, they&amp;#8217;re both using the exact same version of Debian that their server farm uses. So the scope for incompatibilities is hugely reduced. But Alice and Bob still get to use the same text editors, IDEs and other dev tools they rely on &amp;mdash; their VMs augment the capabilities of their original OSes, but don&amp;#8217;t replace them. This is not really a new idea, but end-user virtualization tools like &lt;a href="http://www.vagrantup.com/"&gt;Vagrant&lt;/a&gt; and automation frameworks such as &lt;a href="http://www.saltstack.com/community/"&gt;Salt&lt;/a&gt; have made it much&amp;nbsp;easier.&lt;/p&gt;
&lt;h4&gt;The science&amp;nbsp;bit&lt;/h4&gt;
&lt;p&gt;My goal with &lt;a href="https://github.com/andrewclegg/snake-charmer"&gt;Snake Charmer&lt;/a&gt; is to provide the same hassle-free experience to scientists, engineers, statisticians and data miners. Any two VMs built from the same Snake Charmer config should behave exactly the same, even if they&amp;#8217;re on a completely different hardware or &lt;span class="caps"&gt;OS&lt;/span&gt; platform. And installation needs to be as smooth as possible. When you run Snake Charmer, it does the following, &lt;em&gt;entirely unsupervised&lt;/em&gt;, through the mechanisms provided by Vagrant and&amp;nbsp;Salt:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Downloads a &lt;span class="caps"&gt;VM&lt;/span&gt; image for a specific version of&amp;nbsp;Ubuntu&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Boots this up in &lt;a href="https://www.virtualbox.org/"&gt;VirtualBox&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Installs a precise versioned set of Ubuntu packages, including Python&amp;nbsp;3.4&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Installs an equally exact list of Python packages, patching them where necessary so they play well&amp;nbsp;together&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Starts up an IPython Notebook server on the &lt;span class="caps"&gt;VM&lt;/span&gt;, and gives you its &lt;span class="caps"&gt;URL&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The packages installed include NumPy, SciPy, Pandas, IPython, Matplotlib, Seaborn, scikit-learn, PyMC, statsmodels, PyTables, SymPy, Numexpr, Theano, &lt;span class="caps"&gt;DEAP&lt;/span&gt;, gensim, &lt;span class="caps"&gt;NLTK&lt;/span&gt;, Beautiful Soup, Cython, Numba &lt;a href="https://github.com/andrewclegg/snake-charmer/blob/master/README.md#what-is-included"&gt;and more&lt;/a&gt;. And it even comes bundled with R and Octave, and connectors to plug these into IPython &amp;mdash; on the slim chance you find something that you really can&amp;#8217;t do in&amp;nbsp;Python.&lt;/p&gt;
&lt;p&gt;Of course, since it&amp;#8217;s just a standard Ubuntu box running standard Python, you can install whatever other packages you need, from the &lt;a href="https://pypi.python.org/pypi"&gt;Python package index&lt;/a&gt;, the &lt;a href="http://packages.ubuntu.com/"&gt;Ubuntu repositories&lt;/a&gt; or elsewhere. And if there&amp;#8217;s a package that you need all the time, you can just add it to Snake Charmer&amp;#8217;s config files so that it gets installed automatically any time you need to build a fresh &lt;span class="caps"&gt;VM&lt;/span&gt;. But that&amp;#8217;s just the tip of the iceberg. The fact that these are complete virtual machines, not just software packages, brings all kinds of added&amp;nbsp;benefits.&lt;/p&gt;
&lt;h4&gt;Big fish, little fish, virtual&amp;nbsp;box&lt;/h4&gt;
&lt;p&gt;Here are some of the useful things you can do with VMs, either via Vagrant commands, or through VirtualBox&amp;#8217;s admin&amp;nbsp;app.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Disposability.&lt;/strong&gt; Normally, you wouldn&amp;#8217;t store data or code &lt;em&gt;within&lt;/em&gt; the &lt;span class="caps"&gt;VM&lt;/span&gt;, you would use it to run notebooks and read data files from your physical computer. This means if you mess up your &lt;span class="caps"&gt;VM&lt;/span&gt; somehow, you can just delete it and create a new, identical one. Think of them as disposable commodities that aren&amp;#8217;t even worth&amp;nbsp;fixing.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Snapshots and rollbacks.&lt;/strong&gt; On the other hand, you might want to make some persistent changes to a &lt;span class="caps"&gt;VM&lt;/span&gt;, like trying out a new package, or a new version of a library. You can take a &lt;em&gt;snapshot&lt;/em&gt; of a whole &lt;span class="caps"&gt;VM&lt;/span&gt; before making a change or taking an action, and if necessary, undo it by rolling back the whole &lt;span class="caps"&gt;VM&lt;/span&gt; to the snapshot. You could also use this feature to save the state of the &lt;span class="caps"&gt;VM&lt;/span&gt; at intermediate points along an analysis pipeline. It&amp;#8217;s also a good idea to make a snapshot after you first create a fresh &lt;span class="caps"&gt;VM&lt;/span&gt;, as rolling back is much quicker than installing a new one from&amp;nbsp;scratch.&lt;/p&gt;
&lt;p&gt;This process can be managed via a &lt;a href="https://github.com/dergachev/vagrant-vbox-snapshot"&gt;Vagrant plugin&lt;/a&gt; or through &lt;a href="http://www.howtogeek.com/150258/how-to-save-time-by-using-snapshots-in-virtualbox/"&gt;VirtualBox itself&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Shareability.&lt;/strong&gt; You can bundle up your &lt;span class="caps"&gt;VM&lt;/span&gt; into a &lt;a href="https://docs.vagrantup.com/v2/cli/package.html"&gt;redistributable package&lt;/a&gt;, including any changes you&amp;#8217;ve made to it, and then send it to your colleagues, or make it available for download. Plus you can include data, notebooks and scripts within the package, meaning your entire workflow can be replicated. I believe this has lots of potential in education and in scientific publishing, beyond the more obvious uses in academic and commercial R&amp;amp;D&amp;nbsp;environments.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Collaboration.&lt;/strong&gt; Using &lt;a href="https://vagrantcloud.com/"&gt;Vagrant Cloud&lt;/a&gt;, you can easily let remote users &lt;a href="http://docs.vagrantup.com/v2/share/index.html"&gt;connect to your VMs&lt;/a&gt; over the internet &amp;mdash; either securely authenticated individuals, or anyone with the &lt;span class="caps"&gt;URL&lt;/span&gt;. This is a natural extension of &lt;a href="http://penandpants.com/2013/05/08/broadcasting-ipython-notebooks/"&gt;IPython&amp;#8217;s broadcasting features&lt;/a&gt;, and could be used for collaborative working, running demos, presenting results, or teaching. In general, it won&amp;#8217;t be affected by firewalls, broadband &lt;span class="caps"&gt;NAT&lt;/span&gt;&amp;nbsp;etc.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Resource management.&lt;/strong&gt; You can put &lt;a href="https://github.com/andrewclegg/snake-charmer/blob/master/CUSTOMIZING.md#environment-variables"&gt;hard limits&lt;/a&gt; on the amount of memory, &lt;span class="caps"&gt;CPU&lt;/span&gt; and storage space a &lt;span class="caps"&gt;VM&lt;/span&gt; can consume, so a runaway process can&amp;#8217;t crash your whole computer. (We&amp;#8217;ve all been there&amp;#8230;) And you can &lt;a href="https://docs.vagrantup.com/v2/cli/suspend.html"&gt;suspend&lt;/a&gt; a running &lt;span class="caps"&gt;VM&lt;/span&gt;, freeing up all the resources it&amp;#8217;s using, even if it&amp;#8217;s in the middle of a long-running task &amp;mdash; then &lt;a href="https://docs.vagrantup.com/v2/cli/resume.html"&gt;resume&lt;/a&gt; where you left off&amp;nbsp;later.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Elasticity.&lt;/strong&gt; If your resource limits are too tight, for example there&amp;#8217;s not enough &lt;span class="caps"&gt;RAM&lt;/span&gt; to build a model in, you can extend them any time. If there&amp;#8217;s not enough &lt;em&gt;physical&lt;/em&gt; &lt;span class="caps"&gt;RAM&lt;/span&gt;, &lt;span class="caps"&gt;CPU&lt;/span&gt; or disk space in your computer, you can move the entire &lt;span class="caps"&gt;VM&lt;/span&gt; to a server &amp;mdash; or simply create a new, identical one there. With a bit of extra work you can even host a Snake Charmer &lt;span class="caps"&gt;VM&lt;/span&gt; on cloud services like &lt;a href="https://github.com/mitchellh/vagrant-aws"&gt;Amazon &lt;span class="caps"&gt;EC2&lt;/span&gt;&lt;/a&gt; and professional virtualization platforms like &lt;a href="http://docs.vagrantup.com/v2/vmware/index.html"&gt;VMWare&lt;/a&gt;. And you could even create an &lt;a href="http://ipython.org/ipython-doc/stable/parallel/parallel_intro.html"&gt;IPython cluster&lt;/a&gt; of identical VMs for parallel&amp;nbsp;processing.&lt;/p&gt;
&lt;h4&gt;What&amp;nbsp;next?&lt;/h4&gt;
&lt;p&gt;It&amp;#8217;s still early days for Snake Charmer, which currently provides one version of Python (3.4) on one version of Ubuntu (12.04), and installs over 25 data science packages. I want to keep adding new packages on a regular basis, and stay reasonably up-to-date with new versions of Python and Ubuntu. I plan to create a Python 2.7 build too. At some point in the future it might be possible for me to host pre-built &lt;span class="caps"&gt;VM&lt;/span&gt; images for download, but that would need a sponsor, as I want to keep it entirely&amp;nbsp;free.&lt;/p&gt;
&lt;p&gt;To get started, &lt;a href="https://github.com/andrewclegg/snake-charmer"&gt;clone the git repository&lt;/a&gt;, and follow the steps in the &lt;a href="https://github.com/andrewclegg/snake-charmer/blob/master/README.md"&gt;&lt;span class="caps"&gt;README&lt;/span&gt;&lt;/a&gt;. All you really need to do is install VirtualBox and Vagrant, and run one command. Please let me know how you get on, either here or &lt;a href="https://twitter.com/andrew_clegg"&gt;on Twitter&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note: A previous version of this post talked about &amp;#8216;official releases&amp;#8217; but I&amp;#8217;ve since decided not to do numbered releases. The reason being, it gives a false sense of permanence. A third-party package listed in a numbered release can still &lt;a href="https://github.com/andrewclegg/snake-charmer/commit/83932610d1f04486351094de2e2ddcc292d64e93"&gt;disappear from a repo&lt;/a&gt; which will break a numbered release. It&amp;#8217;s probably better just to ensure that master at any point in time is a valid build. Happy to hear any alternative ideas you might&amp;nbsp;have&amp;#8230;&lt;/em&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andrew Clegg</dc:creator><pubDate>Wed, 04 Jun 2014 00:00:00 +0100</pubDate><guid>tag:www.andrewclegg.org,2014-06-04:tech/SnakeCharmerIntro.html</guid><category>snake charmer</category><category>vagrant</category><category>salt</category><category>virtualbox</category><category>virtualization</category><category>python</category></item><item><title>Lies, Damned Lies and Dataviz</title><link>http://www.andrewclegg.org/news/PearsonLabsBlogPost.html</link><description>&lt;p&gt;I recently gave a talk at the &lt;a href="http://theinnovationenterprise.com/summits/big-data-innovation-summit-london-2014/"&gt;Big Data Innovation Summit&lt;/a&gt; called &lt;a href="http://www.slideshare.net/AndrewClegg1/lies-damned-lies-dataviz"&gt;Lies, Damned Lies &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; Dataviz: Bad visualization, and how to avoid it&lt;/a&gt;. The aim: educate and entertain. I&amp;#8217;m not above resorting to mockery when a graphic is particularly incompetent or manipulative, and I&amp;#8217;ve never had that many laughs from a conference crowd&amp;nbsp;before.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.slideshare.net/AndrewClegg1/lies-damned-lies-dataviz"&gt;&lt;img src="../images/political_example.png" alt="Politicians lie -- who knew" title="Politicians lie -- who knew" width="100%"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pearson Labs asked to write up a short blog post version which is &lt;a href="http://labs.pearson.com/lies-damned-lies-dataviz-when-data-visualization-goes-wrong/"&gt;here&lt;/a&gt; &amp;mdash; enjoy. And if you liked that, I&amp;#8217;ll be revisiting the same subject at a &lt;a href="https://skillsmatter.com/conferences/1959-big-data-exchange-2014#program"&gt;Skills Matter event in November&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andrew Clegg</dc:creator><pubDate>Tue, 03 Jun 2014 00:00:00 +0100</pubDate><guid>tag:www.andrewclegg.org,2014-06-03:news/PearsonLabsBlogPost.html</guid><category>visualization</category><category>events</category></item><item><title>Introduction</title><link>http://www.andrewclegg.org/news/Introduction.html</link><description>&lt;p&gt;Releasing &lt;a href="https://github.com/andrewclegg/snake-charmer"&gt;Snake Charmer&lt;/a&gt; has inspired me to start blogging again, so welcome to the new&amp;nbsp;blog.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;ve had a couple of Wordpress blogs in the past, but this time I&amp;#8217;ve decided to give &lt;a href="http://blog.getpelican.com/"&gt;Pelican&lt;/a&gt; a go, for a bit more control. And because Markdown and&amp;nbsp;Python.&lt;/p&gt;
&lt;p&gt;Pelican&amp;#8217;s basically a toolkit for rendering source documents (Markdown, reStructuredText, AsciiDoc) as static &lt;span class="caps"&gt;HTML&lt;/span&gt; pages, and generating all the usual blogging extras like index pages, category pages and so on. It&amp;#8217;s very flexible, hackable, scriptable and command-line-driven, which is ideal for me. So let&amp;#8217;s see how it&amp;nbsp;goes.&lt;/p&gt;
&lt;p&gt;A note on the blog title, in case you&amp;#8217;re interested. There&amp;#8217;s an &lt;a href="http://www.psychologytoday.com/blog/scientocracy/201401/the-plural-anecdote-is-not-data"&gt;often&lt;/a&gt;-&lt;a href="http://www.ft.com/cms/s/2/634fb176-bf3f-11e3-b924-00144feabdc0.html#axzz33YVGNMQM"&gt;quoted&lt;/a&gt; quotation that goes &amp;#8220;the plural of anecdote is not data,&amp;#8221; referring to the comparative credibility of different kinds of evidence. Or at least, many people seem to think that&amp;#8217;s how it goes &amp;mdash; but without any particular reason to believe so. Ironically, the original quote was &amp;#8220;&lt;a href="http://blog.revolutionanalytics.com/2011/04/the-plural-of-anecdote-is-data-after-all.html"&gt;the plural of anecdote &lt;em&gt;is&lt;/em&gt; data&lt;/a&gt;&amp;#8221; (my&amp;nbsp;emphasis).  &lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andrew Clegg</dc:creator><pubDate>Mon, 02 Jun 2014 00:00:00 +0100</pubDate><guid>tag:www.andrewclegg.org,2014-06-02:news/Introduction.html</guid><category>intro</category><category>test</category><category>pelican</category></item></channel></rss>