<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>The Plural of Anecdote</title><link href="http://www.andrewclegg.org/" rel="alternate"></link><link href="http://www.andrewclegg.org/feeds/tech.atom.xml" rel="self"></link><id>http://www.andrewclegg.org/</id><updated>2017-05-28T00:00:00+01:00</updated><entry><title>Optimizing TensorFlow for your laptop’s CPU</title><link href="http://www.andrewclegg.org/tech/TensorFlowLaptopCPU.html" rel="alternate"></link><updated>2017-05-28T00:00:00+01:00</updated><author><name>Andrew Clegg</name></author><id>tag:www.andrewclegg.org,2017-05-28:tech/TensorFlowLaptopCPU.html</id><summary type="html">&lt;p&gt;I&amp;#8217;ve recently been teaching myself &lt;a href="https://www.tensorflow.org"&gt;TensorFlow&lt;/a&gt;, and haven&amp;#8217;t spent the time and money to set up a cloud server (or physical machine!) with a &lt;span class="caps"&gt;GPU&lt;/span&gt;. I was originally running it from a pre-built Docker image, inside a Jupyter notebook, and saw a bunch of warnings like this in the console&amp;nbsp;output:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
    W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
    W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
    W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
    W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
    W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The pre-built versions available through Docker, pip etc. tend to go for wide compatibility, which means disabling a bunch of optional speedups that aren&amp;#8217;t supported on all hardware. Thankfully, it turns out not to be too hard to build it from scratch yourself, which lets you switch all this good stuff on, and makes the process of experimentation and learning a bit less&amp;nbsp;tedious.&lt;/p&gt;
&lt;p&gt;This could also be useful if you&amp;#8217;re training a model that&amp;#8217;s just too damn big to fit on &lt;span class="caps"&gt;GPU&lt;/span&gt; hardware that you can actually afford, or if you want to train on GPUs but squeeze extra performance out of cheap &lt;span class="caps"&gt;CPU&lt;/span&gt;-based inference servers at query&amp;nbsp;time.&lt;/p&gt;
&lt;p&gt;Here&amp;#8217;s a walkthrough of how I did it, on a 2016 Macbook Pro running Sierra (10.12.5). I expect the steps for Windows and Linux are similar. There are quite a few prerequisites, but it&amp;#8217;s fairly likely you have some of these&amp;nbsp;already.&lt;/p&gt;
&lt;h3&gt;Xcode&lt;/h3&gt;
&lt;p&gt;First off you&amp;#8217;ll need Xcode if you don&amp;#8217;t already have it, you can get this from the App&amp;nbsp;Store.&lt;/p&gt;
&lt;h3&gt;Python&lt;/h3&gt;
&lt;p&gt;TensorFlow works with various different versions of Python, I believe, but I was using the &lt;a href="https://www.continuum.io/downloads"&gt;Anaconda distribution&lt;/a&gt; of Python&amp;nbsp;2.7.&lt;/p&gt;
&lt;h3&gt;Homebrew&lt;/h3&gt;
&lt;p&gt;You&amp;#8217;ll need this if you don&amp;#8217;t have it already, in order to install Bazel (see below). Download it from &lt;a href="https://brew.sh"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Java&lt;/h3&gt;
&lt;p&gt;Bazel also requires &lt;span class="caps"&gt;JDK8&lt;/span&gt; which you can get from &lt;a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html"&gt;Oracle&lt;/a&gt;. I used 1.8.0_131 which was the latest at time of writing, but I don&amp;#8217;t think it matters too&amp;nbsp;much.&lt;/p&gt;
&lt;h3&gt;Bazel&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://bazel.build"&gt;Bazel&lt;/a&gt; is Google&amp;#8217;s build tool which is used to compile and package &lt;span class="caps"&gt;TF&lt;/span&gt;. Once Homebrew and Java are installed &amp;#8212; you may want to log out and log back in again to make sure environment variables etc. are set up right &amp;#8212; you can install Bazel by&amp;nbsp;typing:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;brew install bazel&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;TensorFlow&lt;/h3&gt;
&lt;p&gt;Finally we can actually install TensorFlow&amp;nbsp;itself.&lt;/p&gt;
&lt;p&gt;I created a Conda environment to work in,&amp;nbsp;first:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;conda create -n tensorflow
    source activate tensorflow&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Although I think this is a bit moot, as the pip install step (see below) seems to install it into your Conda site-packages and make it available in all environments&amp;nbsp;automatically.&lt;/p&gt;
&lt;p&gt;Then checkout TensorFlow from &lt;a href="https://github.com/tensorflow/tensorflow"&gt;GitHub&lt;/a&gt; and cd into your local copy,&amp;nbsp;and&lt;/p&gt;
&lt;p&gt;&lt;code&gt;./configure&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;to configure the build. You can switch on various optional features here, it&amp;#8217;s probably fine to leave everything as defaults though. The actual options we&amp;#8217;re interested in aren&amp;#8217;t controlled here, but via command line params when you actually build&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;That&amp;#8217;s done by typing the&amp;nbsp;following:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-msse4.2 -k //tensorflow/tools/pip_package:build_pip_package&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This will compile &lt;span class="caps"&gt;TF&lt;/span&gt; itself, and also output a script to generate a Python package. Be warned, this will take a while! Well over an hour, probably more like two. I didn&amp;#8217;t time it&amp;nbsp;exactly.&lt;/p&gt;
&lt;p&gt;On some platforms you need to add &lt;code&gt;--copt=-mfpmath=both&lt;/code&gt; to the set of flags above, but recent versions of clang provided with macOS don&amp;#8217;t need this, and will barf if you&amp;nbsp;do.&lt;/p&gt;
&lt;p&gt;Once it&amp;#8217;s finished, you need to bundle it into a pip wheel &amp;#8212; a binary distribution with a Python&amp;nbsp;wrapper:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Then you can install this into your Conda environment. First, double-check your paths are set up right by typing &lt;code&gt;which pip&lt;/code&gt; &amp;#8212; it should be pointing to a version of pip in your anaconda install directory. Then&amp;nbsp;type:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pip install /tmp/tensorflow_pkg/tensorflow-&amp;lt;blah&amp;gt;.whl&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;where &lt;code&gt;&amp;lt;blah&amp;gt;&lt;/code&gt; is some long version string. Just tab-complete it &amp;#8212; this should be the only .whl file in that directory&amp;nbsp;anyway.&lt;/p&gt;
&lt;p&gt;Now we can test it works! But before that, and &lt;strong&gt;this is important&lt;/strong&gt;, cd out of the tensorflow directory to somewhere completely different, e.g. your home directory. If you don&amp;#8217;t do this, when you try to import the package, Python will try to import it from the local directory and not the installed library, and fail with a cryptic error. This confused me the first&amp;nbsp;time.&lt;/p&gt;
&lt;p&gt;Anyway, to test it&amp;#8217;s installed &lt;span class="caps"&gt;OK&lt;/span&gt;, run python or ipython,&amp;nbsp;and:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;import tensorflow as tf
    hello = tf.constant('Hello, TensorFlow!')
    sess = tf.Session()
    print(sess.run(hello))&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If this prints a message with no errors, you&amp;#8217;re good to&amp;nbsp;go.&lt;/p&gt;
&lt;p&gt;And we&amp;#8217;re done! I didn&amp;#8217;t do any specific speed comparisons but training and evaluating toy models was noticeably faster with the custom build than it had been before. Of course, some of this may be down to the Docker virtualization overhead, not just the &lt;span class="caps"&gt;CPU&lt;/span&gt; flags, but a win&amp;#8217;s a win &amp;#8212; and you save a load of memory by not using Docker&amp;nbsp;too.&lt;/p&gt;</summary><category term="tensorflow"></category><category term="machine learning"></category><category term="deep learning"></category><category term="osx"></category><category term="macos"></category><category term="mac"></category></entry><entry><title>Kale: timeseries data mining at Etsy</title><link href="http://www.andrewclegg.org/tech/KaleTalk.html" rel="alternate"></link><updated>2015-02-21T00:00:00+00:00</updated><author><name>Andrew Clegg</name></author><id>tag:www.andrewclegg.org,2015-02-21:tech/KaleTalk.html</id><summary type="html">&lt;p&gt;&lt;em&gt;I&amp;#8217;m very pleased to announce that my talk proposal on &lt;a href="https://codeascraft.com/2013/06/11/introducing-kale/"&gt;Kale&lt;/a&gt; v2 has been accepted by both &lt;a href="http://monitorama.com/index.html"&gt;Monitorama 2015&lt;/a&gt; and &lt;a href="http://berlinbuzzwords.de/"&gt;Berlin Buzzwords 2015&lt;/a&gt;. Here&amp;#8217;s the&amp;nbsp;abstract.&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;Signatures, patterns and trends: Timeseries data mining at&amp;nbsp;Etsy&lt;/h4&gt;
&lt;p&gt;Etsy loves metrics. Everything that happens in our data centres gets recorded, graphed and stored. But with over a million metrics flowing in constantly, it’s hard for any team to keep on top of all that information. Graphing everything doesn’t scale, and traditional alerting methods based on thresholds become very prone to false&amp;nbsp;positives.&lt;/p&gt;
&lt;p&gt;That’s why we started Kale, an open-source software suite for pattern mining and anomaly detection in operational data streams. These are big topics with decades of research, but many of the methods in the literature are ineffective on terabytes of noisy data with unusual statistical characteristics, and techniques that require extensive manual analysis are unsuitable when your ops teams have service levels to&amp;nbsp;maintain.&lt;/p&gt;
&lt;p&gt;In this talk I’ll briefly cover the main challenges that traditional statistical methods face in this environment, and introduce some pragmatic alternatives that scale well and are easy to implement (and automate) on Elasticsearch and similar platforms. I’ll talk about the stumbling blocks we encountered with the first release of Kale, and the resulting architectural changes coming in version 2.0. And I’ll go into a little technical detail on the fingerprinting algorithms we use for fast approximate querying of metrics and their associated statistical metadata. These techniques have applications in clustering, outlier detection, similarity search and supervised learning, and they are not limited to the data centre but can be applied to any high-volume timeseries&amp;nbsp;data.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If you can&amp;#8217;t make it to either of these, videos will hopefully be available online soon&amp;nbsp;afterwards.&lt;/em&gt;&lt;/p&gt;</summary><category term="kale"></category><category term="monitoring"></category><category term="alerting"></category><category term="metrics"></category><category term="anomaly detection"></category><category term="devops"></category><category term="talks"></category></entry><entry><title>All your Bayes are belong to us! PyMC, PyStan and emcee in Snake Charmer</title><link href="http://www.andrewclegg.org/tech/AllYourBayes.html" rel="alternate"></link><updated>2014-06-04T00:00:00+01:00</updated><author><name>Andrew Clegg</name></author><id>tag:www.andrewclegg.org,2014-06-04:tech/AllYourBayes.html</id><summary type="html">&lt;p&gt;&lt;a href="https://github.com/pymc-devs/pymc"&gt;PyMC&lt;/a&gt; is the most widely-used Python package for Bayesian modelling, learning and inference, but it isn&amp;#8217;t the only choice, by far. &lt;a href="https://twitter.com/jakevdp"&gt;Jake Vanderplas&lt;/a&gt; recently posted a pretty detailed comparison of PyMC, &lt;a href="http://mc-stan.org/"&gt;PyStan&lt;/a&gt; and &lt;a href="http://dan.iel.fm/emcee/current/"&gt;emcee&lt;/a&gt; on &lt;a href="http://jakevdp.github.io/blog/2014/06/14/frequentism-and-bayesianism-4-bayesian-in-python/"&gt;his blog&lt;/a&gt;, and even if you&amp;#8217;re not an expert in Bayesian methods (I&amp;#8217;m certainly not) I&amp;#8217;d recommend you give it a read. It walks you through the same task in all three packages in order to get a feel for how they work, which is a great way to do&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;As well as functionality, speed and accuracy, Jake also covered installation, and mentioned that PyStan can be painful to install, especially if you don&amp;#8217;t already have a full C/C++ toolset. While many Linux users do, these days a lot of Mac users don&amp;#8217;t, and I&amp;#8217;d hazard a guess that &lt;em&gt;most&lt;/em&gt; Windows users don&amp;#8217;t, even if they program in other languages frequently. Many Python packages need to compile native code during installation, but some of them get round this by offering binaries for various platforms &amp;#8212; although this often not a foolproof solution either. But PyStan also uses the compiler at &lt;em&gt;runtime&lt;/em&gt;, in the process of translating its own model definition language into machine code, so I guess there&amp;#8217;s no easy way for them to build a one-click&amp;nbsp;installer.&lt;/p&gt;
&lt;p&gt;This is exactly the kind of reason why I started &lt;a href="https://github.com/andrewclegg/snake-charmer"&gt;Snake Charmer&lt;/a&gt; in the first place. Installing it and getting the tests passing on Snake Charmer&amp;#8217;s Ubuntu &lt;span class="caps"&gt;VM&lt;/span&gt; was &amp;#8212; well not entirely trivial, but an hour or two at the very most. And once it works for me, it works for everyone. You&amp;#8217;ll now get PyStan and the slightly less fiddly emcee as standard with every Snake Charmer &lt;span class="caps"&gt;VM&lt;/span&gt; &amp;#8212; so, err, forget your unpleasant prior experiences and raise your expectations.&amp;nbsp;(Sorry&amp;#8230;)&lt;/p&gt;
&lt;p&gt;I think this makes Snake Charmer the first Python distribution to include all three of these&amp;nbsp;tools.&lt;/p&gt;
&lt;p&gt;One last note: if you try to reproduce Jake&amp;#8217;s tutorial in Snake Charmer, you may notice some differences. He uses PyMC 2 but Snake Charmer&amp;#8217;s on a pre-release of version 3 already. (Given limited time to work on this, I&amp;#8217;d rather stay ahead of the game&amp;#8230;) However, here&amp;#8217;s a &lt;a href="http://jakevdp.github.io/blog/2014/06/14/frequentism-and-bayesianism-4-bayesian-in-python/#comment-1436231209"&gt;note from Thomas Wiecki&lt;/a&gt; showing the equivalent steps in PyMC&amp;nbsp;3.&lt;/p&gt;</summary><category term="snake charmer"></category><category term="bayes"></category><category term="bayesian"></category><category term="python"></category><category term="statistics"></category><category term="machine learning"></category></entry><entry><title>Snake Charmer: the all-in-one data science toolbox for Python 3</title><link href="http://www.andrewclegg.org/tech/SnakeCharmerIntro.html" rel="alternate"></link><updated>2014-06-04T00:00:00+01:00</updated><author><name>Andrew Clegg</name></author><id>tag:www.andrewclegg.org,2014-06-04:tech/SnakeCharmerIntro.html</id><summary type="html">&lt;p&gt;Python&amp;#8217;s an amazing language, but it&amp;#8217;s constantly let down by its packaging and distribution infrastructure. Apologies to those people who&amp;#8217;ve worked hard to fix this, but it sucks. I&amp;#8217;ve wasted days in the past getting a particular set of packages to cooperate on a particular machine, only to find that the resulting combination of library files, symlinks, chicken blood and chanting doesn&amp;#8217;t work on any &lt;em&gt;other&lt;/em&gt;&amp;nbsp;machines.&lt;/p&gt;
&lt;p&gt;The &lt;a href="http://virtualenv.readthedocs.org/en/latest/"&gt;virtualenv&lt;/a&gt; tool helps a bit, by letting you have entirely separate Pythons, different versions if necessary, with their own sandboxed libraries and tools. But not all packages behave well in virtualenvs. Some are just sloppily written, but others have very specific dependencies on libraries supplied by your operating system or compiler toolchain, which may be written in C or Fortran or Ancient Enochian, and can&amp;#8217;t easily be localized to a virtualenv. Some even have specific hardware requirements, or platform-specific behavioural&amp;nbsp;quirks.&lt;/p&gt;
&lt;p&gt;This is particularly true in scientific and statistical computing, where some of the most popular Python tools make use of low-level libraries for linear algebra or parallel computing, and others rely on &lt;span class="caps"&gt;OS&lt;/span&gt;-dependent features for image rendering or interprocess communication. And behavioural differences and incompatibilities can be particularly pernicious &amp;mdash; maybe your code will run without any errors, but quietly produce &lt;a href="https://github.com/statsmodels/statsmodels/issues/1690"&gt;slightly inaccurate predictions&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;Meanwhile, in&amp;nbsp;Shoreditch&amp;#8230;&lt;/h4&gt;
&lt;p&gt;Thankfully, there&amp;#8217;s a solution to many of these problems, if we borrow an idea from our much hipper web developer friends. These days it&amp;#8217;s quite common to build standardized, pre-packaged virtual machines (VMs) for developers to work in, meaning your code has the same runtime environment as all your teammates&amp;#8217; code does, and this closely resembles the servers you will eventually deploy to. By running a little server inside each developer&amp;#8217;s laptop or desktop, with its own &lt;span class="caps"&gt;OS&lt;/span&gt; and emulated &amp;#8216;hardware&amp;#8217;, you mask the differences between all those machines and the software installed on&amp;nbsp;them.&lt;/p&gt;
&lt;p&gt;Who cares if Alice has Mountain Lion on a MacBook Air, and Bob has Lucid Lynx on a water-cooled tower &lt;span class="caps"&gt;PC&lt;/span&gt; with a Cylon-themed case mod? When they&amp;#8217;re building code and running tests, they&amp;#8217;re both using the exact same version of Debian that their server farm uses. So the scope for incompatibilities is hugely reduced. But Alice and Bob still get to use the same text editors, IDEs and other dev tools they rely on &amp;mdash; their VMs augment the capabilities of their original OSes, but don&amp;#8217;t replace them. This is not really a new idea, but end-user virtualization tools like &lt;a href="http://www.vagrantup.com/"&gt;Vagrant&lt;/a&gt; and automation frameworks such as &lt;a href="http://www.saltstack.com/community/"&gt;Salt&lt;/a&gt; have made it much&amp;nbsp;easier.&lt;/p&gt;
&lt;h4&gt;The science&amp;nbsp;bit&lt;/h4&gt;
&lt;p&gt;My goal with &lt;a href="https://github.com/andrewclegg/snake-charmer"&gt;Snake Charmer&lt;/a&gt; is to provide the same hassle-free experience to scientists, engineers, statisticians and data miners. Any two VMs built from the same Snake Charmer config should behave exactly the same, even if they&amp;#8217;re on a completely different hardware or &lt;span class="caps"&gt;OS&lt;/span&gt; platform. And installation needs to be as smooth as possible. When you run Snake Charmer, it does the following, &lt;em&gt;entirely unsupervised&lt;/em&gt;, through the mechanisms provided by Vagrant and&amp;nbsp;Salt:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Downloads a &lt;span class="caps"&gt;VM&lt;/span&gt; image for a specific version of&amp;nbsp;Ubuntu&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Boots this up in &lt;a href="https://www.virtualbox.org/"&gt;VirtualBox&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Installs a precise versioned set of Ubuntu packages, including Python&amp;nbsp;3.4&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Installs an equally exact list of Python packages, patching them where necessary so they play well&amp;nbsp;together&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Starts up an IPython Notebook server on the &lt;span class="caps"&gt;VM&lt;/span&gt;, and gives you its &lt;span class="caps"&gt;URL&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The packages installed include NumPy, SciPy, Pandas, IPython, Matplotlib, Seaborn, scikit-learn, PyMC, statsmodels, PyTables, SymPy, Numexpr, Theano, &lt;span class="caps"&gt;DEAP&lt;/span&gt;, gensim, &lt;span class="caps"&gt;NLTK&lt;/span&gt;, Beautiful Soup, Cython, Numba &lt;a href="https://github.com/andrewclegg/snake-charmer/blob/master/README.md#what-is-included"&gt;and more&lt;/a&gt;. And it even comes bundled with R and Octave, and connectors to plug these into IPython &amp;mdash; on the slim chance you find something that you really can&amp;#8217;t do in&amp;nbsp;Python.&lt;/p&gt;
&lt;p&gt;Of course, since it&amp;#8217;s just a standard Ubuntu box running standard Python, you can install whatever other packages you need, from the &lt;a href="https://pypi.python.org/pypi"&gt;Python package index&lt;/a&gt;, the &lt;a href="http://packages.ubuntu.com/"&gt;Ubuntu repositories&lt;/a&gt; or elsewhere. And if there&amp;#8217;s a package that you need all the time, you can just add it to Snake Charmer&amp;#8217;s config files so that it gets installed automatically any time you need to build a fresh &lt;span class="caps"&gt;VM&lt;/span&gt;. But that&amp;#8217;s just the tip of the iceberg. The fact that these are complete virtual machines, not just software packages, brings all kinds of added&amp;nbsp;benefits.&lt;/p&gt;
&lt;h4&gt;Big fish, little fish, virtual&amp;nbsp;box&lt;/h4&gt;
&lt;p&gt;Here are some of the useful things you can do with VMs, either via Vagrant commands, or through VirtualBox&amp;#8217;s admin&amp;nbsp;app.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Disposability.&lt;/strong&gt; Normally, you wouldn&amp;#8217;t store data or code &lt;em&gt;within&lt;/em&gt; the &lt;span class="caps"&gt;VM&lt;/span&gt;, you would use it to run notebooks and read data files from your physical computer. This means if you mess up your &lt;span class="caps"&gt;VM&lt;/span&gt; somehow, you can just delete it and create a new, identical one. Think of them as disposable commodities that aren&amp;#8217;t even worth&amp;nbsp;fixing.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Snapshots and rollbacks.&lt;/strong&gt; On the other hand, you might want to make some persistent changes to a &lt;span class="caps"&gt;VM&lt;/span&gt;, like trying out a new package, or a new version of a library. You can take a &lt;em&gt;snapshot&lt;/em&gt; of a whole &lt;span class="caps"&gt;VM&lt;/span&gt; before making a change or taking an action, and if necessary, undo it by rolling back the whole &lt;span class="caps"&gt;VM&lt;/span&gt; to the snapshot. You could also use this feature to save the state of the &lt;span class="caps"&gt;VM&lt;/span&gt; at intermediate points along an analysis pipeline. It&amp;#8217;s also a good idea to make a snapshot after you first create a fresh &lt;span class="caps"&gt;VM&lt;/span&gt;, as rolling back is much quicker than installing a new one from&amp;nbsp;scratch.&lt;/p&gt;
&lt;p&gt;This process can be managed via a &lt;a href="https://github.com/dergachev/vagrant-vbox-snapshot"&gt;Vagrant plugin&lt;/a&gt; or through &lt;a href="http://www.howtogeek.com/150258/how-to-save-time-by-using-snapshots-in-virtualbox/"&gt;VirtualBox itself&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Shareability.&lt;/strong&gt; You can bundle up your &lt;span class="caps"&gt;VM&lt;/span&gt; into a &lt;a href="https://docs.vagrantup.com/v2/cli/package.html"&gt;redistributable package&lt;/a&gt;, including any changes you&amp;#8217;ve made to it, and then send it to your colleagues, or make it available for download. Plus you can include data, notebooks and scripts within the package, meaning your entire workflow can be replicated. I believe this has lots of potential in education and in scientific publishing, beyond the more obvious uses in academic and commercial R&amp;amp;D&amp;nbsp;environments.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Collaboration.&lt;/strong&gt; Using &lt;a href="https://vagrantcloud.com/"&gt;Vagrant Cloud&lt;/a&gt;, you can easily let remote users &lt;a href="http://docs.vagrantup.com/v2/share/index.html"&gt;connect to your VMs&lt;/a&gt; over the internet &amp;mdash; either securely authenticated individuals, or anyone with the &lt;span class="caps"&gt;URL&lt;/span&gt;. This is a natural extension of &lt;a href="http://penandpants.com/2013/05/08/broadcasting-ipython-notebooks/"&gt;IPython&amp;#8217;s broadcasting features&lt;/a&gt;, and could be used for collaborative working, running demos, presenting results, or teaching. In general, it won&amp;#8217;t be affected by firewalls, broadband &lt;span class="caps"&gt;NAT&lt;/span&gt;&amp;nbsp;etc.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Resource management.&lt;/strong&gt; You can put &lt;a href="https://github.com/andrewclegg/snake-charmer/blob/master/CUSTOMIZING.md#environment-variables"&gt;hard limits&lt;/a&gt; on the amount of memory, &lt;span class="caps"&gt;CPU&lt;/span&gt; and storage space a &lt;span class="caps"&gt;VM&lt;/span&gt; can consume, so a runaway process can&amp;#8217;t crash your whole computer. (We&amp;#8217;ve all been there&amp;#8230;) And you can &lt;a href="https://docs.vagrantup.com/v2/cli/suspend.html"&gt;suspend&lt;/a&gt; a running &lt;span class="caps"&gt;VM&lt;/span&gt;, freeing up all the resources it&amp;#8217;s using, even if it&amp;#8217;s in the middle of a long-running task &amp;mdash; then &lt;a href="https://docs.vagrantup.com/v2/cli/resume.html"&gt;resume&lt;/a&gt; where you left off&amp;nbsp;later.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Elasticity.&lt;/strong&gt; If your resource limits are too tight, for example there&amp;#8217;s not enough &lt;span class="caps"&gt;RAM&lt;/span&gt; to build a model in, you can extend them any time. If there&amp;#8217;s not enough &lt;em&gt;physical&lt;/em&gt; &lt;span class="caps"&gt;RAM&lt;/span&gt;, &lt;span class="caps"&gt;CPU&lt;/span&gt; or disk space in your computer, you can move the entire &lt;span class="caps"&gt;VM&lt;/span&gt; to a server &amp;mdash; or simply create a new, identical one there. With a bit of extra work you can even host a Snake Charmer &lt;span class="caps"&gt;VM&lt;/span&gt; on cloud services like &lt;a href="https://github.com/mitchellh/vagrant-aws"&gt;Amazon &lt;span class="caps"&gt;EC2&lt;/span&gt;&lt;/a&gt; and professional virtualization platforms like &lt;a href="http://docs.vagrantup.com/v2/vmware/index.html"&gt;VMWare&lt;/a&gt;. And you could even create an &lt;a href="http://ipython.org/ipython-doc/stable/parallel/parallel_intro.html"&gt;IPython cluster&lt;/a&gt; of identical VMs for parallel&amp;nbsp;processing.&lt;/p&gt;
&lt;h4&gt;What&amp;nbsp;next?&lt;/h4&gt;
&lt;p&gt;It&amp;#8217;s still early days for Snake Charmer, which currently provides one version of Python (3.4) on one version of Ubuntu (12.04), and installs over 25 data science packages. I want to keep adding new packages on a regular basis, and stay reasonably up-to-date with new versions of Python and Ubuntu. I plan to create a Python 2.7 build too. At some point in the future it might be possible for me to host pre-built &lt;span class="caps"&gt;VM&lt;/span&gt; images for download, but that would need a sponsor, as I want to keep it entirely&amp;nbsp;free.&lt;/p&gt;
&lt;p&gt;To get started, &lt;a href="https://github.com/andrewclegg/snake-charmer"&gt;clone the git repository&lt;/a&gt;, and follow the steps in the &lt;a href="https://github.com/andrewclegg/snake-charmer/blob/master/README.md"&gt;&lt;span class="caps"&gt;README&lt;/span&gt;&lt;/a&gt;. All you really need to do is install VirtualBox and Vagrant, and run one command. Please let me know how you get on, either here or &lt;a href="https://twitter.com/andrew_clegg"&gt;on Twitter&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note: A previous version of this post talked about &amp;#8216;official releases&amp;#8217; but I&amp;#8217;ve since decided not to do numbered releases. The reason being, it gives a false sense of permanence. A third-party package listed in a numbered release can still &lt;a href="https://github.com/andrewclegg/snake-charmer/commit/83932610d1f04486351094de2e2ddcc292d64e93"&gt;disappear from a repo&lt;/a&gt; which will break a numbered release. It&amp;#8217;s probably better just to ensure that master at any point in time is a valid build. Happy to hear any alternative ideas you might&amp;nbsp;have&amp;#8230;&lt;/em&gt;&lt;/p&gt;</summary><category term="snake charmer"></category><category term="vagrant"></category><category term="salt"></category><category term="virtualbox"></category><category term="virtualization"></category><category term="python"></category></entry></feed>