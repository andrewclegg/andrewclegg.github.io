<!DOCTYPE html>
<html lang="en">

<head>
  <link rel="stylesheet/less" type="text/css" href="../theme/css/style.less">
  <script src="../theme/js/less-1.3.3.min.js" type="text/javascript"></script>
  <!-- <link rel="stylesheet" type="text/css" href="../theme/css/style.css"> -->

  <link rel="stylesheet" type="text/css" href="../theme/css/pygments.css">
  <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=PT+Sans|PT+Serif|PT+Mono">

  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="author" content="Andrew Clegg">
  <meta name="description" content="Posts and writings by Andrew Clegg">

  <link href="http://www.andrewclegg.org/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="The Plural of Anecdote Full Atom Feed" />

<meta name="keywords" content="tensorflow, machine learning, deep learning, osx, macos, mac">

  <title>
Optimizing TensorFlow for your laptop&#8217;s <span class="caps">CPU</span>  </title>

</head>

<body>
  <aside>
    <div id="user_meta">
      <a href="..">
        <img src="/theme/images/logo.jpg" alt="logo">
      </a>
      <h2><a href="..">Andrew Clegg</a></h2>
      <p>The Plural of Anecdote</p>
      <ul>
        <li><a href="../About.html">About</a></li>
        <li><a href="../Publications.html">Publications</a></li>
        <li><a href="../Talks.html">Talks and&nbsp;workshops</a></li>
        <li><a href="/">Blog posts</a></li>
        <li><a href="https://github.com/andrewclegg/snake-charmer">Snake Charmer</a></li>
        <li><a href="https://github.com/andrewclegg">GitHub</a></li>
        <li><a href="https://twitter.com/andrew_clegg">Twitter</a></li>
        <li><a href="https://www.linkedin.com/in/andrewcleggdatascientist">LinkedIn</a></li>
      </ul>
    </div>
  </aside>

  <main>
    <header>
<p>Posted on Sun 28 May 2017</p>
    </header>

<article>
  <div id="article_title">
    <h3><a href="../tech/TensorFlowLaptopCPU.html">Optimizing TensorFlow for your laptop&#8217;s <span class="caps">CPU</span></a></h3>
  </div>
  <div id="article_text">
    <p>I&#8217;ve recently been teaching myself <a href="https://www.tensorflow.org">TensorFlow</a>, and haven&#8217;t spent the time and money to set up a cloud server (or physical machine!) with a <span class="caps">GPU</span>. I was originally running it from a pre-built Docker image, inside a Jupyter notebook, and saw a bunch of warnings like this in the console&nbsp;output:</p>
<div class="highlight"><pre>W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&#39;t
compiled to use SSE3 instructions, but these are available on your machine and
could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&#39;t
compiled to use SSE4.1 instructions, but these are available on your machine and
could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&#39;t
compiled to use SSE4.2 instructions, but these are available on your machine and
could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&#39;t
compiled to use AVX instructions, but these are available on your machine and
could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&#39;t
compiled to use AVX2 instructions, but these are available on your machine and
could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&#39;t
compiled to use FMA instructions, but these are available on your machine and
could speed up CPU computations.
</pre></div>


<p>The pre-built versions available through Docker, pip etc. tend to go for wide compatibility, which means disabling a bunch of optional speedups that aren&#8217;t supported on all hardware. Thankfully, it turns out not to be too hard to build it from scratch yourself, which lets you switch all this good stuff on, and makes the process of experimentation and learning a bit less&nbsp;tedious.</p>
<p>This could also be useful if you&#8217;re training a model that&#8217;s just too damn big to fit on <span class="caps">GPU</span> hardware that you can actually afford, or if you want to train on GPUs but squeeze extra performance out of cheap <span class="caps">CPU</span>-based inference servers at query&nbsp;time.</p>
<p>Here&#8217;s a walkthrough of how I did it, on a 2016 Macbook Pro running Sierra (10.12.5). I expect the steps for Windows and Linux are similar. There are quite a few prerequisites, but it&#8217;s fairly likely you have some of these&nbsp;already.</p>
<h3>Xcode</h3>
<p>First off you&#8217;ll need Xcode if you don&#8217;t already have it, you can get this from the App&nbsp;Store.</p>
<h3>Python</h3>
<p>TensorFlow works with various different versions of Python, I believe, but I was using the <a href="https://www.continuum.io/downloads">Anaconda distribution</a> of Python&nbsp;2.7.</p>
<h3>Homebrew</h3>
<p>You&#8217;ll need this if you don&#8217;t have it already, in order to install Bazel (see below). Download it from <a href="https://brew.sh">here</a>.</p>
<h3>Java</h3>
<p>Bazel also requires <span class="caps">JDK8</span> which you can get from <a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html">Oracle</a>. I used 1.8.0_131 which was the latest at time of writing, but I don&#8217;t think it matters too&nbsp;much.</p>
<h3>Bazel</h3>
<p><a href="https://bazel.build">Bazel</a> is Google&#8217;s build tool which is used to compile and package <span class="caps">TF</span>. Once Homebrew and Java are installed &#8212; you may want to log out and log back in again to make sure environment variables etc. are set up right &#8212; you can install Bazel by&nbsp;typing:</p>
<div class="highlight"><pre>brew install bazel
</pre></div>


<h3>TensorFlow</h3>
<p>Finally we can actually install TensorFlow&nbsp;itself.</p>
<p>I created a Conda environment to work in,&nbsp;first:</p>
<div class="highlight"><pre>conda create -n tensorflow
source activate tensorflow
</pre></div>


<p>Although I think this is a bit moot, as the pip install step (see below) seems to install it into your Conda site-packages and make it available in all environments&nbsp;automatically.</p>
<p>Then checkout TensorFlow from <a href="https://github.com/tensorflow/tensorflow">GitHub</a> and cd into your local copy,&nbsp;and</p>
<div class="highlight"><pre>./configure
</pre></div>


<p>to configure the build. You can switch on various optional features here, it&#8217;s probably fine to leave everything as defaults though. The actual options we&#8217;re interested in aren&#8217;t controlled here, but via command line params when you actually build&nbsp;it.</p>
<p>That&#8217;s done by typing the&nbsp;following:</p>
<div class="highlight"><pre>bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-msse4.2 -k \
  //tensorflow/tools/pip_package:build_pip_package
</pre></div>


<p>This will compile <span class="caps">TF</span> itself, and also output a script to generate a Python package. Be warned, this will take a while! Well over an hour, probably more like two. I didn&#8217;t time it&nbsp;exactly.</p>
<p>On some platforms you need to add <code>--copt=-mfpmath=both</code> to the set of flags above, but recent versions of clang provided with macOS don&#8217;t need this, and will barf if you&nbsp;do.</p>
<p>Once it&#8217;s finished, you need to bundle it into a pip wheel &#8212; a binary distribution with a Python&nbsp;wrapper:</p>
<div class="highlight"><pre>bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
</pre></div>


<p>Then you can install this into your Conda environment. First, double-check your paths are set up right by typing <code>which pip</code> &#8212; it should be pointing to a version of pip in your anaconda install directory. Then&nbsp;type:</p>
<div class="highlight"><pre>pip install /tmp/tensorflow_pkg/tensorflow-&lt;blah&gt;.whl
</pre></div>


<p>where <code>&lt;blah&gt;</code> is some long version string. Just tab-complete it &#8212; this should be the only .whl file in that directory&nbsp;anyway.</p>
<p>Now we can test it works! But before that, and <strong>this is important</strong>, cd out of the tensorflow directory to somewhere completely different, e.g. your home directory. If you don&#8217;t do this, when you try to import the package, Python will try to import it from the local directory and not the installed library, and fail with a cryptic error. This confused me the first&nbsp;time.</p>
<p>Anyway, to test it&#8217;s installed <span class="caps">OK</span>, run python or ipython,&nbsp;and:</p>
<div class="highlight"><pre>import tensorflow as tf
hello = tf.constant(&#39;Hello, TensorFlow!&#39;)
sess = tf.Session()
print(sess.run(hello))
</pre></div>


<p>If this prints a message with no errors, you&#8217;re good to&nbsp;go.</p>
<p>And we&#8217;re done! I didn&#8217;t do any specific speed comparisons but training and evaluating toy models was noticeably faster with the custom build than it had been before. Of course, some of this may be down to the Docker virtualization overhead, not just the <span class="caps">CPU</span> flags, but a win&#8217;s a win &#8212; and you save a load of memory by not using Docker&nbsp;too.</p>
  </div>
  <div id="article_meta">
    <p>Category: <a href="../tech/index.html">tech</a></p>
    <p>Tags:
      <a href="../tag/tensorflow.html">tensorflow</a>,      <a href="../tag/machine-learning.html">machine learning</a>,      <a href="../tag/deep-learning.html">deep learning</a>,      <a href="../tag/osx.html">osx</a>,      <a href="../tag/macos.html">macos</a>,      <a href="../tag/mac.html">mac</a>    </p>
    <p>&nbsp;</p>
    <!--
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'thepluralofanecdote'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
  </div>
  -->
</article>

    <footer>
<p><a href="../" class="button_accent">&larr; Back to Index</a></p>
    </footer>

    <div id="ending_message">
      <p><em><strong>No comments?</strong> I'm no longer sure blog comments are relevant. I'd rather you replied on <a href="https://twitter.com/andrew_clegg">Twitter</a>, or wrote a response on your own blog or a site like <a href="https://medium.com/">Medium</a>.</em></p>
      <p>All content (cc) Andrew Clegg, under <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 License</a>. Built on <a href="http://getpelican.com">Pelican</a> &amp; <a href="http://python.org">Python</a>. Theme based on <a href="https://github.com/giulivo/pelican-svbhack">svbhack</a> by Giulio Fidente.</p>
    </div>
  </main>
</body>
</html>